# Project Understanding: kev-new-graph-rag Hybrid RAG System

This document outlines the current understanding of the `kev-new-graph-rag` project, including its objectives, architecture, core technologies, data pipelines, and configuration management. It serves as a reference for ongoing development.

## 1. Project Goal

The primary objective is to develop a sophisticated hybrid Retrieval Augmented Generation (RAG) system. This system aims to answer natural language queries by leveraging:
1.  A structured knowledge graph built with **Graphiti** and stored in **Neo4j AuraDB**, capturing entities and their evolving temporal relationships.
2.  A vector store (**ChromaDB**) containing text chunks and semantic embeddings from ingested documents.

The system should be able to perform complex reasoning, especially considering the temporal aspects of the data within the knowledge graph.

## 2. Core Technologies & Frameworks

*   **Graphiti (`graphiti-core`):**
    *   Used for knowledge graph extraction from structured and unstructured data.
    *   Central to modeling temporal relationships with properties like `valid_at`, `invalid_at`, `created_at`, `expired_at`, and `reference_time` on edges.
    *   Supports episodic ingestion and data namespacing via `group_id`.
    *   The project intends to use Graphiti's native capabilities for querying, moving away from LlamaIndex wrappers.
    *   Local repository (dependency, not to be modified): `c:\Users\kevin\repos\graphiti\graphiti_core`
    *   Examples directory (dependency): `c:\Users\kevin\repos\graphiti\examples`
*   **Neo4j AuraDB:** The primary graph database storing the knowledge graph generated by Graphiti.
*   **ChromaDB:** A vector database used to store text chunks from source documents and their corresponding vector embeddings (generated by Gemini).
*   **Google Gemini (via `google-genai` SDK):**
    *   The core Large Language Model (LLM) for various tasks, including:
        *   Natural Language to Cypher (NL-to-Cypher) translation.
        *   Generating text embeddings.
        *   Potentially other generative tasks.
    *   This is the **unified Python SDK for Google's Gemini models**. It can target both the Gemini Developer API (often using API keys) and the Gemini API on Vertex AI (using Application Default Credentials - ADC - by setting the `GOOGLE_GENAI_USE_VERTEXAI=True` environment variable along with `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION`).
    *   The project will use this SDK for all Gemini model interactions, configured to point to Vertex AI for consistency with other GCP services and ADC authentication.
    *   It supports structured output capabilities crucial for tasks like Cypher query generation.
    *   The older `google-generativeai` SDK is deprecated and **must not** be used. The `google-cloud-aiplatform` SDK, while capable, is superseded by `google-genai` for direct Gemini model interactions as per latest Google guidance for a unified interface.
*   **Python:** The primary programming language for the entire project.
*   **Pydantic:** Used for defining data schemas, including:
    *   The project's `universal_ontology.py`.
    *   Models for enforcing structured output from Gemini LLM calls.

## 3. Data Ingestion Pipeline

The current ingestion pipeline (`scripts/ingest_gdrive_documents.py`) performs the following steps:
1.  **Data Source:** Documents are fetched from a specified Google Drive folder.
2.  **Parsing:** Documents are parsed (previously using LlamaParse).
3.  **Graph Extraction:** Graphiti's `GraphExtractor` processes the parsed content using the defined `universal_ontology.py` to extract entities and relationships.
4.  **Storage:**
    *   **Neo4j:** Extracted graph data (nodes and temporal relationships) is ingested into the Neo4j AuraDB instance.
    *   **ChromaDB:** Text chunks from the documents are stored along with their Gemini-generated embeddings.

## 4. Ontology (`src/ontology_templates/universal_ontology.py`)

The project employs a universal ontology designed for multi-domain knowledge extraction, covering AI research, geopolitical analysis, YouTube transcripts, etc. It is defined in `C:\Users\kevin\repos\kev-new-graph-rag\src\ontology_templates\universal_ontology.py`.

*   **Core Entity Types (9):** `Person`, `Organization`, `Location`, `Event`, `Technology`, `Content`, `Topic`, `Resource`, `Agreement`.
*   **Universal Relationship Types (10):** `Participates`, `Located`, `Creates`, `Uses`, `Supports`, `Opposes`, `Discusses`, `Controls`, `Collaborates`, `Influences`.
*   **Temporal Properties:** All relationship models include `fact: str`, `valid_at: Optional[datetime]`, and `invalid_at: Optional[datetime]` to support Graphiti's temporal modeling.
*   **Pydantic Base:** All ontology models inherit directly from `pydantic.BaseModel`.

## 5. Configuration Management

Configuration is managed externally to avoid hardcoding and facilitate different environments/setups.

*   **`.env` File:**
    *   Location: `C:\Users\kevin\repos\kev-new-graph-rag\.env`
    *   Stores sensitive information and environment-specific settings:
        *   Neo4j credentials (`NEO4J_URI`, `NEO4J_USER`, `NEO4J_PASSWORD`, `NEO4J_DATABASE`).
        *   API keys (`GOOGLE_API_KEY`, `ANTHROPIC_API_KEY`, `PERPLEXITY_API_KEY`, `OPENAI_API_KEY`, `LLAMA_CLOUD_API_KEY`).
        *   Google Cloud project details (`GOOGLE_CLOUD_PROJECT`, `GOOGLE_CLOUD_LOCATION`).
        *   **Vertex AI Integration (`GOOGLE_GENAI_USE_VERTEXAI`): Must be set to `True` to enable authentication via Application Default Credentials (ADC) and direct API calls to Vertex AI instead of the standard Gemini API.**
        *   Google Drive integration paths and credentials.
        *   ChromaDB connection details (`CHROMA_HOST`, `CHROMA_PORT`, auth details).
*   **`config.yaml` File:**
    *   Location: `C:\Users\kevin\repos\kev-new-graph-rag\config.yaml`
    *   Stores non-sensitive application configurations:
        *   Gemini model IDs for 'pro' and 'flash' versions, and default thinking budgets.
        *   Gemini embeddings model ID and output dimensionality.
        *   Neo4j retry configurations (max_retries, delay_seconds).
        *   Logging level.

**All scripts should load configurations from these files.** New configurable parameters should be added to these files as appropriate.

## 6. Key Project Directories and Files

### Directories
*   **Project Root:** `C:\Users\kevin\repos\kev-new-graph-rag\`
*   **Ontology:** `src\ontology_templates\universal_ontology.py`
*   **Ingestion Scripts:** `scripts\` (e.g., `ingest_gdrive_documents.py`)
*   **Graph Querying Module:** `src\graph_querying\`
*   **Project Documentation:** `Project Documentation\`
*   **Graphiti Core (Dependency):** `c:\Users\kevin\repos\graphiti\graphiti_core\`
*   **Graphiti Examples (Dependency):** `c:\Users\kevin\repos\graphiti\examples\`

### Key Files

#### Graph Querying Implementation
*   **Graphiti Native Search:** `src\graph_querying\graphiti_native_search.py`
    * Implements hybrid search using Graphiti's native search capabilities
    * Integrates custom Gemini embeddings with Graphiti's search and reranking
    * Provides multiple search methods: hybrid_search, entity_focused_search, advanced_search_with_recipe

*   **Test Script:** `src\graph_querying\test_hybrid_search.py`
    * Validates embedding compatibility (1536-dimensional embeddings)
    * Tests all search methods with various queries
    * Confirms proper authentication and integration

*   **Custom Embedding:** `src\utils\embedding.py`
    *   Contains the `CustomGeminiEmbedding` class, which serves as the primary mechanism for generating Gemini text embeddings (1536-dimensional, `models/embedding-001`) within the project.
    *   **Rationale for Custom Implementation vs. Graphiti's `GeminiEmbedder`:**
        *   **Vertex AI ADC Integration:** `CustomGeminiEmbedding` is explicitly designed to use Google Cloud Vertex AI with Application Default Credentials (ADC). It correctly sets the `GOOGLE_GENAI_USE_VERTEXAI=True` environment variable and manages `GOOGLE_CLOUD_PROJECT` and `GOOGLE_CLOUD_LOCATION`, ensuring seamless authentication in the GCP environment. Graphiti's built-in `GeminiEmbedder` (as of `graphiti-core v0.12.0`) is primarily oriented towards API key-based authentication with the Google AI Gemini API and lacks this explicit Vertex AI ADC setup.
        *   **`task_type` and `title` Parameter Support:** The custom class passes `task_type` (e.g., "RETRIEVAL_DOCUMENT", "RETRIEVAL_QUERY") and an optional `title` to the Gemini embedding API. These parameters are recommended by Google for optimizing embedding quality for specific use cases, which is crucial for a high-performance RAG system. Graphiti's `GeminiEmbedder` does not currently support these parameters.
        *   **LlamaIndex Compatibility:** `CustomGeminiEmbedding` inherits from `llama_index.core.embeddings.BaseEmbedding`, allowing for direct integration with LlamaIndex components used elsewhere in the ingestion pipeline.
        *   **Centralized Configuration:** It sources model names and dimensionality from the project's central `config.yaml`, promoting consistency.
    *   This approach provides a robust and tailored embedding solution that meets the project's specific architectural and authentication requirements, offering more control and feature utilization than the generic embedder provided by Graphiti at the time of this decision.

#### Graphiti Integration Files
*   **Gemini Integration:** `graphiti_core\embedders\gemini.py` (in Graphiti dependency)
    * Contains `GeminiEmbedder` and `GeminiEmbedderConfig` classes
    * Supports configurable embedding model and dimensionality
    * Can be used with ADC authentication for production environments

## 7. Query Pipeline Status: Pivot Complete & Validated

*   The initial strategy using LlamaIndex's `TextToCypherRetriever` was abandoned due to persistent integration issues.
*   The project successfully **pivoted to a direct NL-to-Cypher pipeline** built in `src/graph_querying/cypher_generator.py`.
*   This new pipeline uses the `google-genai` SDK to interact with Gemini, enforcing structured JSON output via Pydantic models.
*   **Validation:** The end-to-end pipeline has been successfully validated. It can take a natural language query, generate a syntactically correct and schema-aware Cypher query, and execute it against the Neo4j database without technical errors.
*   **Current Focus:** The challenge has shifted from technical implementation to data investigation. The pipeline works, but initial queries returned zero results, indicating a mismatch between the assumed relationship names in the query (e.g., `r.name = 'CREATES'`) and how Graphiti actually stored those relationships in the database. The next step is to inspect the Neo4j graph to discover the correct relationship properties and update the LLM prompt accordingly.

## 8. SDK and Development Requirements

*   **`google-genai` SDK:** Strict adherence to using the latest `google-genai` Python SDK for all interactions with Google Gemini models.
*   **Structured Output:** Leverage Gemini's structured output features (e.g., JSON mode with Pydantic schemas) for predictable and reliable LLM responses, especially for Cypher query generation.
*   **Modularity:** New code, particularly for the query engine, should be modular and well-organized within the `src/graph_querying/` directory.

This document will be updated as the project evolves.
