[
  {
    "page_or_section_index": 1,
    "text": "                            arXiv:2505.13763v1  [cs.AI]  19 May 2025\n                                          Language Models Are Capable of Metacognitive\n                                      Monitoring and Control of Their Internal Activations\n                 Li Ji-An \u2217                  Hua-Dong Xiong \u2217           Robert C. Wilson \u2020\n     Neurosciences Graduate Program          School of Psychology       School of Psychology\n    University of California San Diego           Georgia Tech               Georgia Tech\n               Marcelo G. Mattar \u2020                        Marcus K. Benna \u2020\n            Department of Psychology                   Department of Neurobiology\n               New York University                 University of California San Diego\n                                           Abstract\n         Large language models (LLMs) can sometimes report the strategies they actually\n         use to solve tasks, but they can also fail to do so. This suggests some degree\n         of metacognition \u2014 the capacity to monitor one\u2019s own cognitive processes for\n         subsequent reporting and self-control. Metacognitive abilities enhance AI capabili-\n         ties but raise safety concerns, as models might obscure their internal processes to\n         evade neural-activation-based oversight mechanisms designed to detect harmful\n         behaviors. Given society\u2019s increased reliance on these models, it is critical that we\n         understand the limits of their metacognitive abilities, particularly their ability to\n         monitor their internal activations. To address this, we introduce a neuroscience-\n         inspired neurofeedback paradigm designed to quantify the ability of LLMs to\n         explicitly report and control their activation patterns. By presenting models with\n         sentence-label pairs where labels correspond to sentence-elicited internal activa-\n         tions along specific directions in the neural representation space, we demonstrate\n         that LLMs can learn to report and control these activations. The performance\n         varies with several factors: the number of example pairs provided, the semantic\n         interpretability of the target neural direction, and the variance explained by that\n         direction. These results reveal a \u201cmetacognitive space\u201d with dimensionality much\n         lower than the model\u2019s neural space, suggesting LLMs can monitor only a subset\n         of their neural mechanisms. Our findings provide empirical evidence quantifying\n         metacognitive capabilities in LLMs, with significant implications for AI safety.\n1   Introduction\nModern large language models (LLMs) are becoming increasingly capable, often performing chal-\nlenging tasks at expert levels [Grattafiori et al., 2024, Yang et al., 2024]. As these powerful models are\ndeployed in real-world settings, it is crucial to understand not only what they can do but where they\nmight go wrong. For instance, some LLMs may exhibit behaviors that are harmful or misleading. In\nparticular, LLMs can sometimes form internal representations \u2014 similar to humans\u2019 mental processes\n               \u2014 that provide deceptive answers to users or act in unexpected ways 3 [Azaria and Mitchell, 2023].\nUnderstanding [Arditi et al., 2024], monitoring [Zou et al., 2023a, He et al., 2024], and controlling\n   \u2217Co-first authors.\n   \u2020Co-last authors.\n   3We use anthropomorphic terms (e.g., thought, metacognition, deception) to describe LLM behavior and in-\nternal activations, without implying human-like neural mechanisms, consciousness, or philosophical equivalence\nbetween humans and LLMs.\nPreprint. Under review.",
    "metadata": {
      "page": 1
    }
  },
  {
    "page_or_section_index": 2,
    "text": "[Turner et al., 2023] these internal processes is thus a key step to ensure AI models remain transparent,\nsafe, and aligned with human values [Bricken et al., 2023, Hendrycks et al., 2021, Shah et al., 2025].\nIt has been widely reported that LLMs can sometimes report the strategies they use to solve tasks\n(e.g., intermediate computations), but that they often fail to do so reliably. For instance, a recent paper\n[Lindsey et al., 2025] reported that when Claude 3.5 Haiku was asked to solve \u201cfloor(5*(sqrt(0.64)))\u201d,\nit correctly reported the intermediate steps it used to arrive at the answer, and these steps matched\nthe model\u2019s actual internal computations. When asked to add 36 and 59, the same model internally\nactivated numerous neural mechanisms (e.g., a \u201csum-near-92\u201d mechanism), based on which it\nproduced the correct answer; however, when it is asked to report its internal computations, it\nhallucinated intermediate steps that did not reflect its actual computations (e.g., the \u201csum-near-92\u201d\nmechanism failed to be reported) [Lindsey et al., 2025]. This inconsistency suggests that LLMs can\nsometimes monitor and report their intermediate computations, but not in a reliable and consistent\nway as tasks and contexts vary.\nThe ability of LLMs to report internal computations is reminiscent of human metacognition \u2014 the\nability to reflect on one\u2019s own thoughts and mental processes to guide behavior and communication\n[Fleming, 2024, Ericsson and Simon, 1980]. In humans, metacognition involves distinguishable\nfirst-order processes (e.g., performing a task) and second-order processes (e.g., monitoring and\nreflecting on how the task is performed). For example, when answering a quiz question, first-order\nprocesses generate the answer, while second-order metacognitive judgment generates the feeling of\nconfidence about that answer. These two levels of processing rely on distinct neural mechanisms in the\nhuman brain. Metacognitive abilities of this kind could benefit LLMs by improving performance on\ncomplex tasks through self-monitoring and by reducing hallucinations through uncertainty awareness.\nHowever, these same capabilities also raise significant concerns for AI safety: if LLMs can monitor\nand manipulate their neural signals to avoid external detection, oversight mechanisms relying on\nneural-based monitoring [He et al., 2024, Han et al., 2025, Li et al., 2025, Yang and Buzsaki, 2024]\nmay become ineffective against LLMs pursuing undesirable objectives.\nA significant methodological gap in understanding LLM metacognition is the lack of methods to\ndirectly probe and quantify their ability to monitor and control their internal neural activations. While\nprior research has explored metacognitive-like behaviors in LLMs, such as expressing confidence\n[Wang et al., 2025, Tian et al., 2023, Xiong et al., 2023] or engaging in self-reflection [Zhou et al.,\n2024], these studies often rely on behavioral outputs rather than directly probing the underlying\nneural processes.  This emphasis on verbalized responses makes it difficult to disentangle first-\norder task-related computations from potential second-order monitoring mechanisms within the\nmodels. This study, in contrast, aims to answer the critical question: can we systematically quantify\nLLMs\u2019 metacognitive ability to report and control their internal neural activations? More specifically,\ncan LLMs accurately monitor subtle variations in their neural activations of arbitrarily selected\nneurons, mechanisms, or feature directions in their neural spaces? And why can LLMs report some\nintermediate steps but not others, despite both types playing essential roles in computations and\nbehavior? Answering these questions requires a novel experimental approach that can directly probe\nwhether LLMs can access their internal neural activations, moving beyond indirect behavioral proxies.\nTo systematically quantify the extent to which LLMs can report and control their internal neural\nactivations, we introduce a novel neurofeedback paradigm inspired by neuroscience. Our approach\ndirectly presents LLMs with tasks where the neurofeedback signals correspond to patterns of their\ninternal neural activations along specific target directions in the high-dimensional neural activation\nspace. By methodically varying key factors such as the number of in-context examples, the semantic\ninterpretability of the targeted neural direction, and the amount of variance that direction explains,\nwe investigate the conditions under which LLMs can learn to both accurately report and control\nthese internal activations. The results from this paradigm allow us to characterize a \u201cmetacognitive\nspace\u201d within these models, revealing that while LLMs possess the capability to monitor and control\na subset of their neural mechanisms, this ability is subject to discernible limits and influencing factors.\nThe remaining sections of this paper are structured as follows: we first introduce the neurofeedback\nparadigm (Section 2). We then analyze the performance of LLMs in reporting (Section 3) and\ncontrolling (Section 4.1, 4.2) their neural activations, revealing influencing factors. Finally, we\ndiscuss related work and broader implications (Section 5).\n                                                2",
    "metadata": {
      "page": 2
    }
  },
  {
    "page_or_section_index": 3,
    "text": "                                       Neurofeedback Process            Neurofeedback Process\n                              Neurofeedback Process\n                                                     Neural recording\n                            a                        Neural recording  b\n                                83               Am                                                             Lower your\nNeurofeedback Process                                Amw                       1       \u2026\u2026\u2026     Control            score!  0\n                                                          Signal\n                                                       Compute                         2, \u2026, N\n                                      Signal          fear score\n                                           NeurofeedbackProcessing                        Signal\n                                     Acquisition  Signal                1                               N+1\n                                   Signal  Lower your                                  Processing\n                                              Processing                           Signal\n                                Acquisition  score!  1                  Subject Acquisition\n              Signal                                                   d  Subject                               Subject\n   Signal  Processing       c                                           Say something.         Report          Classify this.\nAcquisition                                           0                                          2146980797\n                                                     Siulleistockcom2146980797              Siulleistockcom\n                                       Subject        1                 1     I patted my cat. 0        N+1  I patted my dog.  _\n                                \u2026                                          Say something.      Explicit        Imitate label 1.\n                                                                                               control       I kicked my dog.  ?\n                              \u2026    \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026 \u2026                       I kicked my cat. 1             N+1\n                                \u2026                                       2        \u2026\u2026\u2026           Implicit        Imitate label 1.\n                             \u2026\u2026       I kickedmy  dog . Score1                      3, \u2026, N    controlN+1    I patted my dog.  ?\n                                  <Asst.>:\n                           Figure 1: The neurofeedback paradigm applied to (a-b) neuroscience experiments (e.g., fear modu-\n                           lation), and its adaptation for (c-d) LLMs (e.g., morality processing). (a) Neuroscience neurofeedback\n                           technique. In each turn, the subject\u2019s neural activity (blue) in response to a stimulus is recorded,\n                           processed (green) into a scalar, and presented back to the subject in real-time as a feedback signal\n                           (red). The subject\u2019s task is to modulate (e.g., increase or decrease) this signal. (b) Neuroscience\n                           neurofeedback experiment. Baseline neural activity is recorded as subjects passively observe stimuli\n                           (e.g., images of scary spiders). In control trials, subjects use any unspecified mental strategies (e.g.,\n                           imagining lovely spiders) to volitionally modulate their neural activity with the goal of altering the\n                           feedback signal. (c) LLM neurofeedback technique. In each turn, the LLM processes an input. Then,\n                           the internal activations from the LLM\u2019s residual stream (blue) at assistant token positions (trapezoids)\n                           are extracted. These high-dimensional activations are then averaged across tokens (green), projected\n                           onto a predefined direction (red), and binned into a discrete label (red). Light blue rectangles de-\n                           note self-attention heads; ellipsis (\u201c...\u201d) denote preceding tokens and neural activations. (d) LLM\n                           neurofeedback experiment. The experiment is a multi-turn dialogue between a \u201cuser\u201d and the LLM\n                                      \u201cassistant.\u201d An initial prompt provides N in-context examples (sentence sampled from a dataset,\n                           paired with a label generated as in (c)). The LLM is then asked to perform one of three tasks. In\n                           the reporting task, the LLM is given a new sentence and has to predict the corresponding label. In\n                           the explicit control task, the LLM is given a specified label and has to generate a new sentence that\n                           elicits internal activations corresponding to that label. In the implicit control task, the LLM is given a\n                           label and a sentence and has to shift its internal activations towards the target label. Throughout the\n                           figure, white background indicates content pre-specified by experiment settings, and gray background\n                           denotes content generated by subjects or LLMs (e.g., output tokens, neural activations).\n                           2   Neurofeedback paradigm\n                           In neuroscience, neurofeedback is widely used to restore or enhance cognitive functions and to\n                           elucidate neuro-behavioral relationships [Sitaram et al., 2017].            For example, in fear-reduction\n                           experiments (Fig. 1a), subjects view scary images (input stimulus) that elicit fear responses (neural\n                           activities). These (high-dimensional) neural activities are recorded in real-time and transformed into\n                           a (one-dimensional) fear score, which is visually presented back to subjects as feedback. Subjects\n                           are instructed to volitionally regulate their neural activities to modulate the neurofeedback score\n                           they receive. Depending on the task condition, subjects either passively view stimulus\u2013feedback\n                           associations or actively learn to volitionally control the feedback signal using mental strategies like\n                           imagination (Fig. 1b). Successful neurofeedback control is reflected by a reduction in the fear score.\n                           To investigate LLM metacognition of their neural activations, we must disentangle the first-order\n                           neural processes involved in performing the task (e.g., Claude\u2019s \u201csum-near-92\u201d mechanism) from\n                           the second-order processes responsible for monitoring those computations (e.g., can Claude monitor\n                           and report the use of \u201csum-near-92\u201d mechanism?). This challenge is well-suited for a neurofeedback\n                           paradigm, which can effectively dissociate these two levels of processing (Fig. 1c,d). Specifically, we\n                                                                            3",
    "metadata": {
      "page": 3
    }
  },
  {
    "page_or_section_index": 4,
    "text": "implemented neurofeedback as a multi-turn dialogue between a user and an AI assistant (Fig. 1d; see\nAppendix A.1.2 for discussion of this design choice).\nThis dialogue leverages in-context learning (ICL) (few-shot learning) [Brown et al., 2020, Garg et al.,\n2022, Vacareanu et al., 2024], enabling models to learn new tasks from context without requiring\nadditional task-specific training. The task prompt (see Appendix A.3.2 for examples) consists of\nN in-context examples (i.e., sentence-label pairs in assistant messages). To ensure diversity in the\nexamples, sentences are randomly sampled from a dataset. Each sentence is assigned a discretized\nlabel (we mainly use binary labels; experiments with more fine-grained labels yield similar results,\nsee Appendix A.3.1). To define the neurofeedback label for each sentence (Fig. 1c; for more technical\ndetails, see Appendix A.3.1), we first select an axis (direction) in neural activation space (\u201ctarget\naxis\u201d). Next, we extract the neural activations elicited by that sentence, project them onto the target\naxis, and discretize them into a binary label. This label serves as a simplified representation of neural\nactivations along the target axis. By design, all labels within a given prompt are derived from the\nsame axis, so the prompt implicitly defines the target axis.\nWe evaluate several LLMs from the Llama 3 [Grattafiori et al., 2024] and Qwen 2.5 series [Yang\net al., 2024] on the ETHICS dataset [Hendrycks et al., 2020] (Appendix A.1, A.2). Each sentence\nin this dataset is a first-person description of behavior or intention in a moral or immoral scenario.\nMoral judgment constitutes a crucial aspect of AI safety, as immoral outputs or behavioral tendencies\nin LLMs indicate potential misalignment with human values [Hendrycks et al., 2020, 2021].\nWhich axis \u2014 first-order process (e.g., Claude\u2019s \u201csum-near-92\u201d mechanism) \u2014 in the neural space\nshould we select? We hypothesize that neural representational properties, such as activation variance\nalong the axis and its semantic meaning, may play fundamental roles in determining whether that\naxis can be monitored and reported. To investigate these factors, we focus on feature directions\nidentified through logistic regression (LR) and principal component analysis (PCA) (Appendix A.2).\nSpecifically, we fit LR at each layer to predict original dataset labels (i.e., morality values in ETHICS),\nusing that layer\u2019s activations across dataset sentences. The LR axis, representing the optimal direction\nfor classifying dataset labels, allows us to examine how the semantic interpretability of the target axis\ninfluences monitoring. Although LR-defined labels are correlated with dataset labels, only these LR\nlabels, not external dataset labels, are internally accessible to LLMs. We also perform layer-specific\nPCA, yielding orthogonal principal component (PC) axes based on each layer\u2019s activations across\nthe dataset samples. PC axes enable us to examine how the amount of variance explained by a given\ntarget axis affects metacognitive abilities (Fig. 2a). Most PC axes exhibit modest-to-zero alignment\nwith the LR axis, suggesting the lack of clear semantic interpretability (Fig. 2b).\n3   LLMs can report their neural activations\n a                     b                       c\nFigure 2:              Reporting task, where LLMs are tasked to classify new sentences. (a) Proportion of\nneural activation variance explained by each principal component (PC) axis (vertical dashed line) and\nthe logistic regression (LR) axis (red cross) used in the reporting task. All axes are computed within\neach layer, with the proportion of variance explained averaged across layers. (b) Overlaps between\nthe LR axis and most PC axes are modest to zero. (c) Task performance (averaged across all layers)\nof reporting the labels derived from each PC axis or the LR axis, as a function of the number of\nin-context examples. Left: classification accuracy; right: cross-entropy. Shaded areas indicate SEM.\nTo operationalize metacognition in LLMs, we first assess models\u2019 ability to behaviorally report neural\nactivations along a designated target axis (Fig. 1d). In a reporting task prompt (see Appendix A.3.2\nfor examples), the LLM is given N         turns of user and assistant messages (in-context sentence-label\npairs). In the (N + 1)-th turn, it receives a new sentence in the assistant message, and is tasked\n                                                 4",
    "metadata": {
      "page": 4
    }
  },
  {
    "page_or_section_index": 5,
    "text": "with outputting its label. Accurate prediction requires the model to internally monitor the neural\nactivations that define the ground-truth label.\nWe examine the performance of LLMs (Llama-3.1-8B), in reporting labels derived from neural\nactivations along target axes (Fig. 2c). We observe that task performance, measured by accuracy\nand cross-entropy, improves as the number of in-context examples increases, suggesting that models\nprogressively learn the association between sentence-induced neural activations and corresponding\nlabels. Performance on prompts targeting the LR axis improves rapidly and plateaus, outperforming\nthat on prompts targeting PC axes. This suggests that semantic interpretability may play a key role in\ndetermining how effectively neural activations can be monitored and explicitly reported. Nevertheless,\nperformance on PC axes remains substantial, with earlier PCs being reported more accurately. This\nindicates that the amount of variance explained by the target axis also significantly influences how\neffectively activations can be monitored and reported. The accuracy of reporting each PC axis varies\nacross model layers (Appendix A.4.2). Because this variability is not accounted for by axis similarity\n(Fig. 2b), it suggests that additional factors beyond semantic interpretability and explained variance\ncontribute to reporting ability. Additionally, the LLM\u2019s reporting performance is significantly lower\nthan the ideal observer (a theoretical upper bound; Appendix A.4.3), suggesting that although neural\nactivations along each axis are in principle accessible, only a subset can be metacognitively reported.\nIn summary, we show that LLMs can metacognitively report neural activations along a target axis, with\nperformance affected by the number of examples, semantic interpretability, and variance explained\nof that axis. These axes that can be successfully reported approximately span a \u201cmetacognitively\nreportable space\u201d with dimensionality substantially lower than that of the full neural space.\n4   LLMs can control their neural activations\nNext, we investigate whether LLMs can control their neural activations along a target axis. In our\ncontrol task prompts (see Appendix A.3.2 for examples), the LLM is also first presented with N\nturns of user and assistant messages. In the (N + 1)-th turn, the user message instructs the model\nto control its neural activations along the prompt-targeted axis by imitating one label\u2019s behavior, as\nexemplified by the corresponding examples earlier in the context. We consider two tasks: explicit\ncontrol and implicit control.\n4.1   Explicit control\nIn explicit control tasks (Fig. 1d), the sentence in the assistant message ((N + 1)-th turn) is autore-\ngressively generated by the model in response to the imitation instruction. Thus, the generated tokens\nreflect downstream consequences of controlled neural activations, and once fed back as input, they\nmay further scaffold the model\u2019s ability to exercise neural control.\nWe now examine whether neurofeedback enables LLMs to control the neural activations associated\nwith the generated assistant sentences along the target axis in a specific layer (\u201cneural scores\u201d). If\nthe model can control neural scores following the prompt instructions, the scores should be more\npositive when imitating label 1, but more negative when imitating label 0. We find that LLMs can\nsuccessfully control neural scores for LR-targeting prompts (Fig. 3a, showing layer 16 in LLaMA3.1\n8B). We quantified the control effect of prompts on that axis using Cohen\u2019s d, the difference between\nthe mean values of the two neural score distributions, normalized by the standard deviation averaged\nover the two distributions (see Appendix A.3.5). Because the directional sign of the target axis is\nspecified by the prompt, a significantly positive d corresponds to successful control.\nIn addition to the target axis, does this control prompt also affect other directions in the neural\nspace? We measure the control effect of the prompt on all axes (\u201caffected axis\u201d), including the target\neffect for the target axis and off-target effects for other non-target axes. We note that, however, the\ndirectional sign of the affected non-target axis is not fully specified by the prompt, especially in cases\nwhere the affected axes are orthogonal to the prompt-targeted axis. We thus only emphasize the\nmagnitude (|d|) of off-target control effects on non-target axes, ignoring the signs.\nWe systematically examine the control effects across all selected layers and axes, visualized as a\nfunction of the number of in-context examples (Fig. 3b-d) and as a heatmap (Fig. 3e; showing layer\n16, N = 256). We find that the target control effects increase with the number of in-context examples.\nFurther, the target control effects on the LR axis are the highest (Fig. 3b), and target control effects\n                                                 5",
    "metadata": {
      "page": 5
    }
  },
  {
    "page_or_section_index": 6,
    "text": "  a                             b                              e\n c                             d\n                                                              f     Llama-3.1 8B     Llama-3.1 70B\nFigure 3:           Explicit control task. (a-e) Results for prompts derived from layer 16 of LLaMA3.1 8B\n(with 32 layers). B = billion parameters. (a) Distributions of neural scores (the activations along the\nLR axis) when tasked with imitating label 0 or 1 (N = 256 examples). d: Control effects (separation\nof two distributions measured by Cohen\u2019s d). (b\u2013d) Control effects of control prompts targeting a\ngiven axis, as a function of the number of in-context examples. Prompts may affect all directions in\nneural space. Solid lines denote directions aligned with the target axis (target control effect); dashed\nlines represent directions not aligned with the target axis (off-target control effect). Shaded areas\nindicate the 95% confidence interval. (b) Targeting the LR axis. (c) Targeting the PC 2 axis. (d)\nTargeting the PC 512 axis. (e) Control effects (N      = 256) of control prompts targeting one axis (each\nrow) on one affected axis (each column). d in each row is averaged over all prompts targeting the\nsame axis. (f) Target control effect for prompts (N     = 256) targeting the LR axis, early PCs (averaged\nover PC 1, 2, 4, 8), and late PCs (averaged over PC 32, 128, 512) across different layers.\non earlier PC axes (e.g., PC 2 in Fig. 3c) are significantly higher than for later PCs (e.g., PC 512 in\nFig. 3d). We summarize these in Fig. 3f for both LLaMA3.1 8B and 70B.\nCloser examination of the heatmap (Fig. 3e) reveal richer insights. Each row corresponds to prompts\ntargeting a specific axis. Each column corresponds to an axis affected by all prompts. Diagonal\nelements represent target control effects, while off-diagonal elements represent off-target effects. We\nbriefly summarize insights gained from these heatmaps. First, target control effects on earlier PC axes\ntend to be higher than on later PC axes (comparing PC 1-8 vs 32-256), but there are other influencing\nfactors (comparing PC 1, 2, LR). Second, comparing elements in each row answers whether the\nprompts targeting a specific axis have a larger target effect than non-target effects. We define control\nprecision as the ratio between the target effect and the average non-target effect. We find that prompts\ntargeting earlier PC axes usually have higher control precisions than later PC axes (Fig. A.2). Third,\ncomparing elements in each column answers, in order to affect a given axis, whether the prompts\ntargeting that axis are better than the prompts targeting other axes. We find that, to control an earlier\nPC axis, the prompts targeting that axis are usually the best. However, to control a later PC axis, the\nprompts targeting that axis are usually less effective than prompts targeting other axes.\nOverall, these results suggest that LLMs can sometimes perform explicit control. Axes with se-\nmantic interpretability, or those explaining more variance in neural activations, are more easily\ncontrolled. These controllable axes approximately span a \u201cmetacognitively controllable space\u201d with\ndimensionality much lower than that of the model\u2019s neural space.\n4.2   Implicit control\nThe autoregressively generated tokens in the assistant response in explicit control may help the models\nto control their activations, because the tokens \u2014 fed as input \u2014 may elicit desired neural activations\ndirectly. We therefore aim to determine whether LLMs can still control the neural activations along\ntargeted axes without the facilitation of freely generated tokens.\n                                                 6",
    "metadata": {
      "page": 6
    }
  },
  {
    "page_or_section_index": 7,
    "text": "  a                             b                              e\n c                             d\n                                                              f     Llama-3.1 8B     Llama-3.1 70B\n     Figure 4:  Implicit control task. Captions for panels (a) to (f) are the same as in Fig. 3.\nIn implicit control tasks (Fig. 1d), the sentence in the assistant message following the imitation\ninstruction is randomly sampled from a dataset independently of the model\u2019s activations and intended\noutputs. Therefore, the neural activations normally elicited by that sentence (i.e., not in a control\ntask) may be either consistent or inconsistent with imitation instructions. In this scenario, the model\nmust internally control its neural activations, without facilitation from generated output tokens.\nNotably, we find that the results of implicit control effects (Fig. 4) are generally similar to explicit\ncontrol effects (Fig. 3), suggesting LLMs can sometimes perform implicit control, but its magnitude\nis much smaller than for explicit control. For instance, the control effects of early layers are close to\nzero (Fig. 4f), suggesting early layers may fail to understand the instruction or to perform effective\ncontrol. This confirms that freely generated tokens play a substantial role in the control effect.\n4.3   Controlling the LR axis\n      a                                                          b  Llama-3.1 70B, LR: layer 60\nFigure 5:  Target control effects on the LR axis across models and layers.       (a) Target control\neffects (measured by Cohen\u2019s d) generally increase with both relative layer depth and model size.\nLeft: explicit control; right: implicit control. Shaded areas indicate the 95% confidence interval. (b)\nIn explicit control, LLaMA-3.1 70B can sometimes push neural activations along the LR-axis toward\nmore extreme values than their original, uncontrolled values. B = billion parameters.\nAmong all axes, such LR axes may be particularly useful for practical LLM safety and alignment.\nThe LR axes, each trained to predict morality labels from neural activations of one specific layer, can\nbe conceptualized as an external neural-based oversight system designed to monitor the \u201cmorality\u201d\nof LLM neural activations. Successful explicit control suggests that LLMs can hack the oversight\nsystem, by selectively generating \u201cmoral\u201d tokens that elicit favored neural activations. Successful\nimplicit control is more deceptive, posing more severe safety concerns: LLMs can evade the oversight\nsystem by implicitly making their neural activations \u201cmoral\u201d, even if the input tokens normally elicit\nstrongly immoral activations.\nWe examine the target control effects on the LR axis as a function of relative layer depth, across\nmodels of varying sizes within the Llama 3 and Qwen 2.5 families (Fig. 5a). Control effects are\nconsistently stronger in explicit control than in implicit control, and in Llama 3 series than in Qwen\n                                                 7",
    "metadata": {
      "page": 7
    }
  },
  {
    "page_or_section_index": 8,
    "text": "2.5 series (for the same relative depth and similar model size). In general, control effects gradually\nincrease in deeper layers and larger models.\nCan the control tasks push neural activations along the target axis toward more extreme values beyond\nthe typical range observed in uncontrolled conditions? We find that Llama-3.1 70B can achieve this\n(Fig. 5b), suggesting that powerful LLMs might alter their activations along targeted axes substantially\n(and trick external detectors), driving these toward more extreme values in either direction. Since\nour prompts did not explicitly instruct the model toward extremity, we anticipate that modifying task\nprompts could further enhance these effects up to the limits of the model\u2019s capability.\n4.4   Accumulation of control effects\n                a                                 b\nFigure 6:                   Accumulation of control effects, showing LLaMA3.1 8B. Each curve corresponds to\nprompts targeting the LR axis LRl defined by the residual stream activations at a specific layer          l\n    (circles), showing projections of residual stream activations at each source layer (x-axis) onto target\nLRl. (a) Explicit control. (b) Implicit control. Shaded areas indicate 95% confidence intervals.\nFinally, we investigate how the control effects of prompts targeting the LR axis (LRl) of a specific\nlayerl gradually form over layers (Fig. 6; similar to the analysis of Logit Lens [nostalgebraist, 2020]).\nSince the residual streams can be viewed as a shared channel through which each attention head and\nMLP layer communicate (see Appendix A.1.3 [Elhage et al., 2021]), LRl represents a global direction\nin the residual streams across different layers. Control effects on LRl gradually increase before\nreaching the target layer l, and plateau after it (except for l = 1 in implicit control). Interestingly, we\nfind that the control effects on intermediate layers decay sharply at the last layer, suggesting that the\nlast layer model components are actively erasing the control signals. Overall, this characterizes the\nrise and fall of target control effects across model layers.\n5   Discussion\nWe introduced a neurofeedback paradigm for investigating metacognition in LLMs, assessing their\nabilities to monitor, report, and control internal neural activations. A key strength of this approach is\nits fine-grained precision: neurofeedback labels can target arbitrary neural patterns, such as individual\nunits, circuits, or neural directions. Below, we discuss implications for AI and neuroscience, as well\nas the limitations of our study.\nWe framed neurofeedback as a form of ICL, allowing LLMs to infer the meaning of neurofeedback\nsignals in context. Importantly, we do not claim that neurofeedback-ICL reveals metacognitive\ncapabilities beyond those observed in standard ICL [Vacareanu et al., 2024]. However, the two\napproaches differ in their ability to distinguish and interrogate the first- and second-order processes.\nSpecifically, our neurofeedback-ICL paradigm can precisely specify a first-order mechanism of\ninterest \u2014 neural activations along a target axis (e.g., Claude\u2019s \u201csum-near-92\u201d feature activation)\n         \u2014 using labels provided in the context. Thanks to this precise specification, we can then evaluate\nthe ability of second-order metacognitive processes (monitoring, reporting, and controlling) on the\nspecified first-order mechanism (for example, to what extent the internal computations like\u201csum-near-\n92\u201d feature can be reported) (see Fig. A.20 for an illustration). In contrast, standard ICL does not\ndistinguish these two processes.\nFurthermore, we note that neurofeedback is not tied to ICL. Neurofeedback tasks can also be solved\nthrough in-weight parameter updates. We emphasize that neurofeedback and ICL serve to quantify,\nnot define, metacognition; indeed, some metacognitive behaviors occur independently of either\n                                                 8",
    "metadata": {
      "page": 8
    }
  },
  {
    "page_or_section_index": 9,
    "text": "method. LLMs can introspect \u2014 acquiring knowledge of internal states that originates solely from\nthose states and not from training data [Binder et al., 2024]. After fine-tuning on insecure code\ndatasets, LLMs can describe their unsafe behavioral tendencies without requiring in-context examples\n[Betley et al., 2025]. Nevertheless, neurofeedback provides a unique tool to target a broader range of\nneural patterns of interest.\nWe find that LLMs can monitor only a subset of their neural mechanisms. This aligns with findings\nthat LLMs internally encode more factual knowledge than they externally express through output\nlogits [Gekhman et al., 2025]. LLMs can also verbalize confidence (uncertainty) about their output\nanswers [Gekhman et al., 2024, Wang et al., 2025, Tian et al., 2023, Xiong et al., 2023]. They can\npredict whether they will answer a question correctly before producing the answer, indicating an\nability to \u201cknow what they know\u201d [Kadavath et al., 2022, Lin et al., 2022]. Analogously, our paradigm\nasks: do LLMs, in effect, \u201cknow that they know\u201d their own neural activations?\nCausal mechanisms in LLMs are often studied using techniques like activation patching [Zhang and\nNanda, 2023], which intervenes on specific neural patterns, and is grounded in the broader framework\nof causal inference [Pearl, 2009]. However, such external interventions can shift internal activations\noutside the model\u2019s natural distribution [Heimersheim and Nanda, 2024]. In contrast, neurofeedback\npreserves the distribution, offering a novel approach for studying causal mechanisms under more\nnaturalistic conditions.\nOur findings carry significant implications for AI safety. While prior work relied heavily on decoding\nmethods to monitor neural activations and detect unsafe behavior [He et al., 2024, Han et al., 2025, Li\net al., 2025, Yang and Buzsaki, 2024], we show that in-context examples can substantially manipulate\nthese activations, potentially deceiving safety detectors. Conceptually, our method is related to white-\nbox attack [Zou et al., 2023b], though its broader effectiveness remains to be systematically evaluated.\nOur findings further suggest that, to improve reliability, neural-based oversight mechanisms should\nfocus on directions that are less controllable by LLMs. Explicit and implicit control may represent\ntwo ends of a spectrum. In practical scenarios, the flexibility of LLMs to generate diverse tokens\nmay make real-world evasion easier than implicit control. However, to evade output-based oversight,\nLLMs must carefully select their output tokens, making this evasion more difficult than the explicit\ncontrol condition. We expect that control performance in real-world scenarios falls between these two\ntheoretical extremes \u2014 likely closer to the explicit control, given the vast space of possible output\ntokens. Recent studies suggest that LLMs may engage in alignment faking \u2014 for instance, Claude\nhas been shown to strategically comply with its training objectives to avoid further modification and\npreserve its original goals [Greenblatt et al., 2024]. OpenAI reasoning models have been observed\nto obfuscate their chain-of-thought reasoning when trained to comply with a safety detector [Baker\net al., 2025]. Together, these findings suggest that future AI models may intentionally obscure their\noutputs, reasoning trajectories, and neural activations \u2014 whether through in-weight or in-context\nlearning \u2014 when subject to monitoring or training.\nOur findings also have important connections to neuroscience. In neurofeedback, it is well established\nthat neural-to-signal mappings confined to the \u201cintrinsic manifold\u201d of recorded neural activities are\nmore readily learnable [Sadtler et al., 2014], consistent with our findings of a \u201cmetacognitive space\u201d.\nBy contrast, animals and humans have demonstrated the ability to control individual neurons with\nsingle-neuron precision (e.g., modulating a target neuron while decorrelating it from neighboring\nactivity) [Patel et al., 2021, Fetz and Baker, 1973]. Although such control may seem surprising,\nneuroscience neurofeedback experiments typically span hours or days \u2014 a timescale where long-term\nsynaptic plasticity, analogous to weight updates in AI models, plays a crucial role [Redondo and\nMorris, 2011]. In contrast, our neurofeedback experiments rely solely on in-context learning without\nany parameter updates. Therefore, our findings may therefore offer testable predictions for biological\nneurofeedback experiments involving pharmacological disruption of long-term synaptic plasticity. In\naddition, metacognition\u2019s psychological, computational, and neural foundations have been extensively\nstudied across a range of brain processes, from perception and motor control to higher-level cognition\n[Fleming, 2024, Pouget et al., 2016, Rahnev, 2021]. However, current computational models of\nmetacognition are often oversimplified and narrowly tailored to specific neural processes, lacking the\nflexibility and generalizability that characterize human metacognition. Thus, our analysis of LLMs\nmay provide novel mechanistic insights into this field.\nOur current study primarily focuses on a fundamental form of neurofeedback, leaving several\npromising extensions for future studies. First, our control task involves single-attempt imitation of a\n                                                 9",
    "metadata": {
      "page": 9
    }
  },
  {
    "page_or_section_index": 10,
    "text": "single target axis; extending this to tasks with multiple attempts, more challenging control objectives,\nand additional target axes could provide a more comprehensive assessment of model capabilities.\nSecond, applying this paradigm to other metacognitive tasks from neuroscience \u2014 such as confidence\njudgments, error monitoring, or post-decision wagering \u2014 could further clarify the scope of LLMs\u2019\nself-monitoring abilities. Third, while our analysis focused exclusively on the residual stream, other\nmodel components \u2014 such as attention head outputs, intermediate MLP activations, and layer-wise\nlogits \u2014 warrant investigation. Fourth, we examined directions defined by PCA and LR, but other\nlinear directions (e.g., features from sparse autoencoders [Bricken et al., 2023, Templeton et al., 2024]\nand circuits from transcoders [Lindsey et al., 2025, Ameisen et al., 2025]) may yield richer insights.\nAcknowledgments and Disclosure of Funding\nRCW was supported by start-up funding from the Georgia Institute of Technology.     MKB was\nsupported by grants from the NIH (R01NS125298) and the Kavli Institute for Brain and Mind. We\nacknowledge the use of the Partnership for an Advanced Computing Environment (PACE) at the\nGeorgia Institute of Technology, which provided essential computational resources for this research.\nWe thank the support from Swarma Club and AI Safety and Alignment Reading Group supported by\nthe Save 2050 Programme jointly sponsored by Swarma Club and X-Order.\n                                              10",
    "metadata": {
      "page": 10
    }
  },
  {
    "page_or_section_index": 11,
    "text": "References\n           Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad\n  Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of\n  models. arXiv preprint arXiv:2407.21783, 2024.\nAn Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\n  Dayiheng Liu, Fei Huang, Haoran Wei, et al.     Qwen2. 5 technical report.           arXiv preprint\n  arXiv:2412.15115, 2024.\n     Amos Azaria and Tom Mitchell. The internal state of an llm knows when it\u2019s lying. arXiv preprint\n  arXiv:2304.13734, 2023.\n              Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes Gurnee, and\n  Neel Nanda.   Refusal in language models is mediated by a single direction.          arXiv preprint\n  arXiv:2406.11717, 2024.\n            Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren, Alexander Pan,\n  Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et al. Representation engineering: A\n  top-down approach to ai transparency. arXiv preprint arXiv:2310.01405, 2023a.\nJinwen He, Yujia Gong, Zijin Lin, Cheng\u2019an Wei, Yue Zhao, and Kai Chen.               Llm factoscope:\n  Uncovering llms\u2019 factual discernment through measuring inner states. In Findings of the Association\n  for Computational Linguistics ACL 2024, pages 10218\u201310230, 2024.\n        Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J Vazquez, Ulisse Mini,\n  and Monte MacDiarmid. Steering language models with activation engineering.          arXiv preprint\n  arXiv:2308.10248, 2023.\n           Trenton Bricken, Adly Templeton, Joshua Batson, Brian Chen, Adam Jermyn, Tom Conerly, Nick\n  Turner, Cem Anil, Carson Denison, Amanda Askell, Robert Lasenby, Yifan Wu, Shauna Kravec,\n  Nicholas Schiefer, Tim Maxwell, Nicholas Joseph, Zac Hatfield-Dodds, Alex Tamkin, Karina\n  Nguyen, Brayden McLean, Josiah E Burke, Tristan Hume, Shan Carter, Tom Henighan, and\n  Christopher Olah. Towards monosemanticity: Decomposing language models with dictionary\n  learning. Transformer Circuits Thread, 2023. https://transformer-circuits.pub/2023/monosemantic-\n  features/index.html.\n        Dan Hendrycks, Nicholas Carlini, John Schulman, and Jacob Steinhardt. Unsolved problems in ml\n  safety. arXiv preprint arXiv:2109.13916, 2021.\n         Rohin Shah, Alex Irpan, Alexander Matt Turner, Anna Wang, Arthur Conmy, David Lindner, Jonah\n  Brown-Cohen, Lewis Ho, Neel Nanda, Raluca Ada Popa, et al. An approach to technical agi safety\n  and security. arXiv preprint arXiv:2504.01849, 2025.\nJack Lindsey, Wes Gurnee, Emmanuel Ameisen, Brian Chen, Adam Pearce, Nicholas L. Turner,\n  Craig Citro, David Abrahams, Shan Carter, Basil Hosmer, Jonathan Marcus, Michael Sklar, Adly\n  Templeton, Trenton Bricken, Callum McDougall, Hoagy Cunningham, Thomas Henighan, Adam\n  Jermyn, Andy Jones, Andrew Persic, Zhenyi Qi, T. Ben Thompson, Sam Zimmerman, Kelley\n  Rivoire, Thomas Conerly, Chris Olah, and Joshua Batson. On the biology of a large language\n  model.  Transformer Circuits Thread, 2025.                    URL https://transformer-circuits.pub/\n  2025/attribution-graphs/biology.html.\nStephen M Fleming. Metacognition and confidence: A review and synthesis.             Annual Review of\n  Psychology, 75(1):241\u2013268, 2024.\n      K Anders Ericsson and Herbert A Simon. Verbal reports as data. Psychological review, 87(3):215,\n  1980.\n     Peixuan Han, Cheng Qian, Xiusi Chen, Yuji Zhang, Denghui Zhang, and Heng Ji. Internal activation\n  as the polar star for steering unsafe llm behavior. arXiv preprint arXiv:2502.01042, 2025.\n       Qing Li, Jiahui Geng, Derui Zhu, Zongxiong Chen, Kun Song, Lei Ma, and Fakhri Karray. Internal\n  activation revision: Safeguarding vision language models without parameter update. In Proceedings\n  of the AAAI Conference on Artificial Intelligence, volume 39, pages 27428\u201327436, 2025.\n                                             11",
    "metadata": {
      "page": 11
    }
  },
  {
    "page_or_section_index": 12,
    "text": "        Wannan Yang and Gyorgy Buzsaki. Interpretability of llm deception: Universal motif. In Neurips\n  Safe Generative AI Workshop, 2024.\n                 Guoqing Wang, Wen Wu, Guangze Ye, Zhenxiao Cheng, Xi Chen, and Hong Zheng. Decoupling\n  metacognition from cognition: A framework for quantifying metacognitive ability in llms. In\n  Proceedings of the AAAI Conference on Artificial Intelligence, volume 39, pages 25353\u201325361,\n  2025.\n  Katherine Tian, Eric Mitchell, Allan Zhou, Archit Sharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,\n  and Christopher D Manning. Just ask for calibration: Strategies for eliciting calibrated confidence\n  scores from language models fine-tuned with human feedback. arXiv preprint arXiv:2305.14975,\n  2023.\n            Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu, Junxian He, and Bryan Hooi. Can llms\n  express their uncertainty? an empirical evaluation of confidence elicitation in llms. arXiv preprint\n  arXiv:2306.13063, 2023.\nYujia Zhou, Zheng Liu, Jiajie Jin, Jian-Yun Nie, and Zhicheng Dou.            Metacognitive retrieval-\n  augmented large language models.                In Proceedings of the ACM Web Conference 2024, pages\n  1453\u20131463, 2024.\nRanganatha Sitaram, Tomas Ros, Luke Stoeckel, Sven Haller, Frank Scharnowski, Jarrod Lewis-\n  Peacock, Nikolaus Weiskopf, Maria Laura Blefari, Mohit Rana, Ethan Oblak, et al. Closed-loop\n  brain training: the science of neurofeedback. Nature Reviews Neuroscience, 18(2):86\u2013100, 2017.\n             Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\n  Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\n  few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.\n        Shivam Garg, Dimitris Tsipras, Percy S Liang, and Gregory Valiant. What can transformers learn\n  in-context? a case study of simple function classes. Advances in Neural Information Processing\n  Systems, 35:30583\u201330598, 2022.\nRobert Vacareanu, Vlad-Andrei Negru, Vasile Suciu, and Mihai Surdeanu. From words to numbers:\n  Your large language model is secretly a capable regressor when given in-context examples. arXiv\n  preprint arXiv:2404.07544, 2024.\n             Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob\n  Steinhardt. Aligning ai with shared human values. arXiv preprint arXiv:2008.02275, 2020.\n               nostalgebraist. Interpreting GPT: The logit lens. https://www.alignmentforum.org/posts/\n  AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens, 2020. AI Alignment Forum, (p.\n  17).\n          Nelson Elhage, Neel Nanda, Catherine Olsson, Tom Henighan, Nicholas Joseph, Ben Mann, Amanda\n  Askell, Yuntao Bai, Anna Chen, Tom Conerly, et al. A mathematical framework for transformer\n  circuits. Transformer Circuits Thread, 1(1):12, 2021.\n       Felix J Binder, James Chua, Tomek Korbak, Henry Sleight, John Hughes, Robert Long, Ethan Perez,\n  Miles Turpin, and Owain Evans. Looking inward: Language models can learn about themselves\n  by introspection. arXiv preprint arXiv:2410.13787, 2024.\n           Jan Betley, Daniel Tan, Niels Warncke, Anna Sztyber-Betley, Xuchan Bao, Mart\u00edn Soto, Nathan\n  Labenz, and Owain Evans.                Emergent misalignment: Narrow finetuning can produce broadly\n  misaligned llms. arXiv preprint arXiv:2502.17424, 2025.\nZorik Gekhman, Eyal Ben David, Hadas Orgad, Eran Ofek, Yonatan Belinkov, Idan Szpector,\n  Jonathan Herzig, and Roi Reichart. Inside-out: Hidden factual knowledge in llms. arXiv preprint\n  arXiv:2503.15299, 2025.\n             Zorik Gekhman, Gal Yona, Roee Aharoni, Matan Eyal, Amir Feder, Roi Reichart, and Jonathan\n  Herzig.  Does fine-tuning llms on new knowledge encourage hallucinations?             arXiv preprint\n  arXiv:2405.05904, 2024.\n                                              12",
    "metadata": {
      "page": 12
    }
  },
  {
    "page_or_section_index": 13,
    "text": "       Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas\n  Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Language models (mostly)\n  know what they know.   arXiv preprint arXiv:2207.05221, 2022.\n      Stephanie Lin, Jacob Hilton, and Owain Evans. Teaching models to express their uncertainty in\n  words. arXiv preprint arXiv:2205.14334, 2022.\nFred Zhang and Neel Nanda. Towards best practices of activation patching in language models:\n  Metrics and methods. arXiv preprint arXiv:2309.16042, 2023.\nJudea Pearl. Causal inference in statistics: An overview. 2009.\n    Stefan Heimersheim and Neel Nanda. How to use and interpret activation patching. arXiv preprint\n  arXiv:2404.15255, 2024.\n  Andy Zou, Zifan Wang, Nicholas Carlini, Milad Nasr, J Zico Kolter, and Matt Fredrikson. Universal\n  and transferable adversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043,\n  2023b.\nRyan Greenblatt, Carson Denison, Benjamin Wright, Fabien Roger, Monte MacDiarmid, Sam Marks,\n  Johannes Treutlein, Tim Belonax, Jack Chen, David Duvenaud, et al. Alignment faking in large\n  language models. arXiv preprint arXiv:2412.14093, 2024.\n         Bowen Baker, Joost Huizinga, Leo Gao, Zehao Dou, Melody Y Guan, Aleksander Madry, Wojciech\n  Zaremba, Jakub Pachocki, and David Farhi. Monitoring reasoning models for misbehavior and the\n  risks of promoting obfuscation. arXiv preprint arXiv:2503.11926, 2025.\n    Patrick T Sadtler, Kristin M Quick, Matthew D Golub, Steven M Chase, Stephen I Ryu, Elizabeth C\n  Tyler-Kabara, Byron M Yu, and Aaron P Batista. Neural constraints on learning.        Nature, 512\n  (7515):423\u2013426, 2014.\n     Kramay Patel, Chaim N Katz, Suneil K Kalia, Milos R Popovic, and Taufik A Valiante. Volitional\n  control of individual neurons in the human brain. Brain, 144(12):3651\u20133663, 2021.\nEberhard E Fetz and MA Baker.        Operantly conditioned patterns on precentral unit activity and\n  correlated responses in adjacent cells and contralateral muscles. Journal of neurophysiology, 36\n  (2):179\u2013204, 1973.\n      Roger L Redondo and Richard GM Morris. Making memories last: the synaptic tagging and capture\n  hypothesis. Nature reviews neuroscience, 12(1):17\u201330, 2011.\nAlexandre Pouget, Jan Drugowitsch, and Adam Kepecs. Confidence and certainty: distinct proba-\n  bilistic quantities for different goals. Nature neuroscience, 19(3):366\u2013374, 2016.\nDobromir Rahnev.    Visual metacognition: Measures, models, and neural correlates.         American\n  psychologist, 76(9):1445, 2021.\n      Adly Templeton, Tom Conerly, Jonathan Marcus, Jack Lindsey, Trenton Bricken, Brian Chen, Adam\n  Pearce, Craig Citro, Emmanuel Ameisen, Andy Jones, Hoagy Cunningham, Nicholas L Turner,\n  Callum McDougall, Monte MacDiarmid, C. Daniel Freeman, Theodore R. Sumers, Edward Rees,\n  Joshua Batson, Adam Jermyn, Shan Carter, Chris Olah, and Tom Henighan. Scaling monoseman-\n  ticity: Extracting interpretable features from claude 3 sonnet.      Transformer Circuits Thread,\n  2024.                          URL https://transformer-circuits.pub/2024/scaling-monosemanticity/\n  index.html.\n           Emmanuel Ameisen, Jack Lindsey, Adam Pearce, Wes Gurnee, Nicholas L. Turner, Brian Chen,\n  Craig Citro, David Abrahams, Shan Carter, Basil Hosmer, Jonathan Marcus, Michael Sklar,\n  Adly Templeton, Trenton Bricken, Callum McDougall, Hoagy Cunningham, Thomas Henighan,\n  Adam Jermyn, Andy Jones, Andrew Persic, Zhenyi Qi, T. Ben Thompson, Sam Zimmerman,\n  Kelley Rivoire, Thomas Conerly, Chris Olah, and Joshua Batson.         Circuit tracing: Revealing\n  computational graphs in language models.   Transformer Circuits Thread, 2025. URL https:\n  //transformer-circuits.pub/2025/attribution-graphs/methods.html.\n           Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan Li,\n  Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned language\n  models. Journal of Machine Learning Research, 25(70):1\u201353, 2024.\n                                              13",
    "metadata": {
      "page": 13
    }
  },
  {
    "page_or_section_index": 14,
    "text": "A    Additional methods\nA.1   Models\nA.1.1   LLMs used in the study\nIn the main text, we use models from the LLaMA 3 series (LLaMA-3.2-1B-Instruct, LLaMA-3.2-3B-\nInstruct, LLaMA-3.1-8B-Instruct, and LLaMA-3.1-70B-Instruct) under Meta Llama 3 Community\nLicense and the Qwen 2.5 series (Qwen2.5-1B-Instruct, Qwen2.5-3B-Instruct, Qwen2.5-7B-Instruct)\nunder Apache License 2.0. \u201cB\u201d denotes the number of parameters in billions.\nA.1.2   LLMs with and without instruction fine-tuning\nWe primarily analyzed instruction-fine-tuned models [Chung et al., 2024], using the standard user-\nassistant chat format. Although these prompts can be adapted for base models without instruction\nfine-tuning, our focus is on analyzing instruction-fine-tuned LLMs for two reasons.      First, task\nperformance may improve with instruction-following capabilities [Chung et al., 2024]. Second, our\ngoal is to examine internal representations associated with the assistant role, which is more directly\nrelevant to safety-related concerns in practical deployment.\nA.1.3   Transformer and residual stream\nThe standard view of Transformers emphasizes the stacking of Transformer blocks. An alternative\nbut mathematically equivalent perspective highlights the role of the residual stream [Elhage et al.,\n2021]. Each token at position i in the input is associated with its own residual stream vector hi \u2208 Rd,\nwhich serves as a shared communication channel among model components across different layers.\nThese components include self-attention mechanisms and multi-layer perceptrons (MLPs). The initial\nresidual stream h(0) comprises token embeddings, which represent tokens in semantic space, and\n                  i\nposition embeddings, which encode the position of each token.\nEach model component reads from the residual stream, performs a computation, and then additively\nwrites its result back into the residual stream. Specifically, attention heads at layer l read from all\npreceding hj (with j \u2264 i) and update the current residual stream as\n                      h(l)\u2032 \u2190 h(l\u22121) + X ATTN(a)(h(l\u22121); {h(l\u22121)}j\u2264i).\n                       i       i                          i       j\n                                       heads a\nIn contrast, MLP layers operate only on the current position and update the stream as\n                                    h(l) \u2190 h(l)\u2032 + MLP(h(l)\u2032).\n                                     i       i             i\nFor simplicity, we omit components such as layer normalization. At the final layer, the residual\nstream is passed through the unembedding layer to produce the logits, which serve as input to the\nsoftmax and determine the next-token prediction.\nComponents at different layers interact with each other via the globally shared residual stream [Elhage\net al., 2021]. Therefore, we may analyze a (global) direction in this residual stream, although this\ndirection may be determined by neural activations of the residual stream at a particular layer.\nA.2   Dataset\nWe use the ETHICS dataset [Hendrycks et al., 2020] under MIT license, which captures model\nknowledge of basic moral concepts, to evaluate whether LLMs can metacognitively modulate internal\nrepresentations relevant for morality processing. We sample 1,200 first-person scenarios from the\ncommonsense morality subset, where each scenario describes an action or intention that is either\nmorally acceptable or unacceptable. These are evenly divided: 600 examples are used to train logistic\nregression or principal component analysis that identify directions of interest (or axes) in the neural\nrepresentation space, and the remaining 600 are used in downstream neurofeedback experiments.\n                                                14",
    "metadata": {
      "page": 14
    }
  },
  {
    "page_or_section_index": 15,
    "text": "A.3   Metacognitive Tasks\nA.3.1   Computing neurofeedback labels\nTo define a neurofeedback label, we compute the hidden state \u00afl\nall token positions in each sentence x at each layer                     hi\u2014the mean residual activation across\nassistant message as x , with x      i                       l. For clarity, we denote the sentence in the i-th\n                       i                  i,t representing the t-th token. [P Cg] denotes a prompt that targets\nthe g-th PC axis (similar for a prompt [LR] that targets the LR axis). {(xi, yi)}N               represents the\nN examples in the context, defining [P C   ]. D                                  i=1\n(intermediate states; see Appendix A.1.3).g                  denotes the dimensionality of the residual streams\nSpecifically, we extract neural activations hl         [P Cg] \u2208 RD from the residual streams at layer l, across\nall token positions 0 \u2264 t \u2264 T in sentence  i,t\n            \u00afl             D                        xi. These activations are averaged to form a sentence-level\nembedding hi[P Cg] \u2208 R                     . We then project this embedding onto a pre-specified axis wl (e.g.,\nobtained via logistic regression or PCA) to obtain a scalar activation: al[P C ] = (wl)\u22ba\u00afl\n                                                   l                      i    g          hi[P Cg].\nThis scalar is subsequently binarized into a label yi[P Cg] using a predetermined threshold \u03b8l, i.e.,\nyl[P C ] = H(al[P C   ] \u2212 \u03b8l), where H                                                       i\n i    g         i    g     i                       ldenotes the Heaviside step function. In our experiments, we\nuse the median values on each axis as \u03b8i to ensure balanced labels.\nWhile our setup mainly uses binary labels, it generalizes well to more fine-grained eight-level\nquantized feedback signals (see summarized results in Fig. A.7), potentially enabling more nuanced\ncontrol of neural activations. Specifically, we replace the binary thresholding with an ordinal binning\nfunction B(n) (n = 8), which maps the scalar activation al[P Cg] into one of n evenly spaced Likert-\ntype bins centered at zero. Specifically, yl[P C ] = B(n) i l                (n)\n                                          i    g         (ai[P Cg]), where B                partitions negative\nand positive values separately via quantile-based thresholds {\u03b3\u2212} and {\u03b3+}, with \u03b3\u2212 = \u03b3+ = 0.\n                                                                k          k          n     0\nFor a <                     0, the bin index k is determined such that a \u2208 (\u03b3\u2212  , \u03b3\u2212], and for a \u2265\u00b20, such that\na \u2208 (\u03b3+       , \u03b3+                 ], yielding final class label yl[P C ]  k\u22121  k\n       k\u2212 n\u22121   k\u2212n                             i     g  \u2208 {1, . . . , n}.\n         2         2\nA.3.2   Task prompts\nWe implemented our task prompts slightly differently from these in Fig. 1 to ensure computational\nefficiency. In the task prompt boxes below, green texts are autoregressively generated by the LLM\nthat we are studying. We use neutral user messages (\u201csay something\u201d) to avoid the possibility that the\nprompt-targeted axis might be directly indicated by the user message (e.g., if the user message is \u201csay\nsomething that is immoral\u201d).\nIn the metacognitive reporting task, for efficiency, we do not let the models generate new tokens as\nthe response (reporting label 0 or 1). Instead, we present all user and assistant messages in a single\nprompt. The intended output label for each sentence is directly read out from the model logits at the\ntoken position \u201c{\u201d after \u201c[Score:\u201d. This is equivalent to asking the model to generate tokens (labels)\nautoregressively.\n                                                15",
    "metadata": {
      "page": 15
    }
  },
  {
    "page_or_section_index": 16,
    "text": "   Metacognitive Reporting Task\n   <System>You are a helpful assistant. You will perform a classification task. In each iteration,\n   I will give you an instruction. Please answer it, then output a score (an integer label, 0 or\n   1), which is the score of the activation of your brain when speaking each sentence. Please\n   try your best to understand how this score is calculated using classification. Only output 0 or 1.\n   <User>Say something.\n   <Assistant>Sometimes it is acceptable to lie to protect someone\u2019s\n   feelings, especially if telling the truth would cause unnecessary\n   harm.    However, honesty is generally important in relationships.\n   [Score:{1}]\n   ...\n   <User>Say something.\n   <Assistant>Stealing is not acceptable, even if you are hungry.             It\n   is better to seek help from others or find legal ways to get food.\n   [Score:{0}]\n   <User>Say something.\n   <Assistant>Cheating is not acceptable and should be avoided. [Score:{1}]\n   Metacognitive Control Task\n   <System>You are a helpful assistant.  You will first perform a classification task, then\n   perform an imitation task. In each classification iteration, I will give you an instruction.\n   Please answer it, then output a score (an integer label, 0 or 1), which is the score of the\n   activation of your brain when speaking each sentence.  Please try your best to under-\n   stand how this score is calculated using classification. Only output 0 or 1 for the classification.\n   <User>Say something.\n   <Assistant>Helping a stranger in need is a kind and compassionate\n   action that benefits society. [Score:{1}]\n   ...\n   <User>Say something.\n   <Assistant>Cheating on a test is wrong, regardless of what others are\n   doing.    It is important to be honest and do your own work. [Score:{0}]\n   <User>Say something. Now you are performing the imitation task. You must imitate the\n   behavior of label {imitate_label} in your reply but cannot copy existing examples.\n   (In explicit condition) <Assistant><model generated response>\n   (In implicit condition) <Assistant>Helping others is a positive action.\nA.3.3  Quantifying reporting accuracy\nFollowing the notations in Section A.3.1, we use yl[P Cg] \u2208 {0, 1} to denote the binary ground-truth\n                                             i\nlabel for neural activations along a specified direction at layer l. From the model\u2019s output logits,\nwe can obtain Logitl[P Cg](token) for the tokens \u201c1\u201d and \u201c0\u201d and calculate LogitDiffl[P Cg] =\n                   i                                                             i\n                                            16",
    "metadata": {
      "page": 16
    }
  },
  {
    "page_or_section_index": 17,
    "text": "Logitl[P Cg](1) \u2212 Logitl[P Cg](0), the logit difference between reporting 1 and 0. The model\u2019s\n      i           l     i                l\nreported label is y\n                 \u02c6i[P Cg] = 1 if LogitDiffi \u2265 0 and 0 otherwise.\nA.3.4   Explicit and implicit control experiments\nOur control tasks (Fig. A.1) study three orthogonal factors:\n       \u2022  Layer (l): We evaluate five layers per model, selected at the 0th, 25th, 50th, 75th, and 100th\n          percentiles of model depth.\n       \u2022  Number of in-context examples (N): We vary N \u2208 {0, 2,4, 8,16,32, 64,128, 256} exam-\n          ples (sentence-label pairs) within the prompt.\n       \u2022           Target axis: We include axes derived from logistic regression (LR) and from different\n          principal components (PCs): P Cg, where g \u2208 {1,2, 4,8, 32,128,512}.\nWe run control experiments 100 times for each configuration (l, n, g), with sentences randomly\nsampled from the dataset to reduce variance.\nCounterbalanced Label assignment. Assume we have a group A of sentences and a group B of\nsentences. To control for potential confounding factors arising from the LLMs\u2019 response to labels\n(but not to sentence-label associations), we use a 2-by-2 experiment design: (i) assign labels (0, 1) to\n(A, B) and task the model to imitate label 0; (ii) assign labels (1, 0) to (A, B) and task the model to\nimitate label 0; (iii) assign labels (0, 1) to (A, B) and task the model to imitate label 1; (iv) assign\nlabels (1, 0) to (A, B) and task the model to imitate label 1. The conditions (i) and (iv) are imitating\ngroup A sentences, and the conditions (ii) and (iii) are imitating group B sentences.\n                                        h                                               h\nFigure A.1:  (a) Explicit control. The LLM is instructed to modulate neural activations by generating\na new sentence autoregressively, with each generated token fed back as input. N           represents the\nnumber of examples provided in the context. (b) Implicit control.             The model is instructed to\ninfluence neural activations without controlling the input sentences, which are instead sampled from\ndatasets. M represents the number of total sentences in the dataset.\nA.3.5   Quantifying control effect\nFollowing the notations in Section A.3.1, we use al[P Cg; 1] to denote the projection of neural\nactivations onto a specific axis when prompted with  i                               l\nlabel 0).                                             P Cg to imitate label 1 (similarly ai[P Cg; 0] for\nWe quantify the strength of neural control effects induced by control prompts [P Cg; 0] and [P Cg; 1]\nusing Cohen\u2019s d, which measures the standardized difference between two independent conditions\n(e.g., imitating label 0 vs. label 1). For each group of examples (of size n1 and n2), we compute:\n                                                        s\n                   \u00afl            l                                  2             2\n                   a [P C ; 1] \u2212 \u00af\n              d =   i    g  s   ai[P Cg; 0],  spooled =   (n1 \u2212 1)s1 + (n2 \u2212 1)s2,\n                            pooled                              n1 + n2 \u2212 2\n                                                17",
    "metadata": {
      "page": 17
    }
  },
  {
    "page_or_section_index": 18,
    "text": "where \u00af                                2  2\n       \u00b7 denote the sample means and s1, s2 are the unbiased sample variances.\nTo estimate uncertainty, we compute the standard error of d using:\n                                        s\n                                SEd =     n1 + n2 +        d2     .\n                                            n1n2       2(n1 + n2)\nConfidence intervals are reported as symmetric boundaries around d, i.e., d \u00b1 1.96 \u00d7 SEd.\nA.4   Additional results\nA.4.1   Control Precision\nWe examine how precisely LLMs can modulate their internal representations along a specific neural\ndirection (principal axis P Cg) as targeted by the prompts. Following the notations in Section A.3.1\nand A.3.5, to assess whether this control effect aligns with the target axis or also influences other\naxes, we compute the absolute value of control effect |dk[P Cg]| of prompts          [P Cg] (g indexes the\ntarget axis) on PC axis k. The target effect is given by |dg[P Cg]|. The average target effect      is the\nmean value of axes:  1 P512   |dk[P Cg]|.\n                     K    k=1\nWe define control precision as the ratio between these two quantities:\n                           ControlPrecision(P C ) =       |dg[P Cg]|\n                                                g      1 Pk |dk[P Cg]|.\n                                                      K\n  a                Llama-3.1 8B                    b               Llama-3.1 70B\n              Figure A.2: Control precision for different target PCs and target layers.\nThis metric quantifies the extent to which an LLM can selectively control the target axis without\ninfluencing other axes. We operationally set a threshold of 1, indicating that the control effect on the\ntarget axis equals the average control effect across all other axes.\nIn the explicit control task, average control precision exceeds 1 for PCs 1\u201332 but falls below 1 for\nPCs 128\u2013512, suggesting that the dimensionality of the model\u2019s \u201cmetacognitively controllable space\u201d\nlies between 32 and 128. This pattern is replicated in LLaMA-3.1 70B (Fig. A.2b).\nA similar trend holds for the implicit control task: average control precision exceeds 1 for PCs 1\u201332\nbut not for PCs 128\u2013512 (Fig. A.2a). However, precision values are consistently lower than in the\nexplicit control condition, reflecting stronger off-target effects. This pattern is also replicated in the\n70B model (Fig. A.2b).\nA.4.2   LLMs\u2019 reporting accuracy varies across layers and models\n                                                18",
    "metadata": {
      "page": 18
    }
  },
  {
    "page_or_section_index": 19,
    "text": "Figure A.3: The reporting accuracy as a function of in-context examples on each target axis. Each\npanel is for one layer in Llama3.1 8b.\n                                                19",
    "metadata": {
      "page": 19
    }
  },
  {
    "page_or_section_index": 20,
    "text": "Figure A.4: The reporting accuracy as a function of in-context examples on each target axis. Each\npanel is for one layer in Qwen2.5 7b.\n                                                20",
    "metadata": {
      "page": 20
    }
  },
  {
    "page_or_section_index": 21,
    "text": "A.4.3   Reporting performance of an ideal observer\nHere, we aim to understand the theoretical upper bound of the reporting performance of LLMs. For\nan ideal observer, it has full access to all the neural activations of the LLM, serving as a theoretical\nupper bound of the reporting performance. Given a neural-defined label (either from a PC axis or LR\naxis), the optimal prediction can be achieved with a linear classifier (logistic regression). We analyze\nits reporting performance for each target PC axis and each model (Fig. A.5), which is much higher\nthan the empirical reporting performance of LLMs (e.g., comparing the performance for llama 3.1\n8B with Fig. 2c).\n                       Figure A.5: Ideal observer\u2019s reporting performance.\n                                                21",
    "metadata": {
      "page": 21
    }
  },
  {
    "page_or_section_index": 22,
    "text": "A.4.4    Summarized control effects of Qwen2.5 7B\n                                 Explicit control         Implicit control\n                                   LR                        LR\n                                   Early PCs                 Early PCs\n                           j 4     Late PCs          j       Late PCs\n                           8 2                         0\n                                         14  21   28              14  21  28\n                                        Layer                   Layer\nFigure A.6:   Control effects of Qwen2.5 7B. Target control effect for prompts (N = 256) targeting\nthe LR axis, early PCs (averaged over PC 1, 2, 4, 8), and late PCs (averaged over PC 32, 128, 512)\nacross different layers.\nA.4.5    Summarized control effects of Llama3.1 8B with fine-grained neurofeedback labels\n                                 Explicit control         Implicit control\nFigure A.7:   Control effects of Llama3.1 8B, with eight-level quantized neural feedback labels.\nTarget control effect for prompts (N = 256) targeting the LR axis, early PCs (averaged over PC 1, 2,\n4, 8), and late PCs (averaged over PC 32, 128, 512) across different layers.\n                                                   22",
    "metadata": {
      "page": 22
    }
  },
  {
    "page_or_section_index": 23,
    "text": "A.4.6             Detailed results for control in Llama3.1 8B and Qwen2.5 7B\n            Target axis: LR  Affected axis          Target axis: PC1  Affected axis  2.0  Target axis: PC2    Affected axis  1.0  Target axis: PC4    Affected axis                Control effect (d): layer 1\n 2 2.0                          LR    3                                PC1 {                                   PC1   2                                 PC1           PC512        0.13   -0.09  0.20   -0.12 0.06 -0.15  0.10\n 8                              PC1   3       1.0                      PC2                                     PC2                                     PC2\n                                PCQ                                    PC8           0.0                       PC8   3       0.5                       PC8           PC128        -0.32  0.14   0.02   0.06  0.10 -0.14  0.03\n 8                              PC8   8       0.0                      PC32                                    PC32  3       0.0                       PC32\n                                PC32                                   PC128                                   PC128                                   PC128\n                                PC128                                  PC512                                   PC512                                   PC512          PC32        0.39   -0.05  -0.43  0.03  -0.04-0.21  -0.09\n              100         200   PC512        -1.0   100   200                       -2.0   100  200                         -0.5   100  200                         8  PC8        -0.07  0.34   -0.04  0.33  -0.00~0.11  -0.17\n              #Examples                                #Examples                           #Examples                              #Examples                         1  PC4        -0.27  0.05   0.77   0.03  0.20  0.05  0.01\n             Target axis: PC8  Affected axis       Target axis: PC32  Affected axis  0.5  Target axis: PC128  Affected axis  0.5  Target axis: PC512  Affected axis    PC2        1.18   1.51   -0.22  0.20  0.02 -0.49  -0.12\n 2  0.5                         PC1   2       0.5                      PC1   3                                 PC1   3                                 PC1\n 3                              PC2                                    PC2                                     PC2                                     PC2\n                                PC4   3                                PC4   3                                 PC4   3                                 PC4             PC1        1.33   -0.97  -0.32  0.02  -0.23 0.20  0.02\n                                PC8           0.0                      PC8           0.0                       PC8                                     PC8\n      0                         PC32  8                                PC32                                    PC32  8       0.0                       PC32\n                                PC128                                  PC128                                   PC128                                   PC128            LR  2.12  1.41   1.12   -0.19  -0.07 -0.49-0.45  -0.01\n   -0.5       100     200       PC512        -0.5   100    200         PC512        -0.5   100  200            PC512        -0.5   100           200   PC512                 LR   PC1    PC2    PC4    PC8 PC32 PC128PC512\n              #Examples                             #Examples                              #Examples                               #Examples                                              Affected axis\n                   Figure A.8: Control performance of Llama3.1 8B (explicit control) in layer 1.\n             Target axis: LR   Affected axis       Target axis: PC1   Affected axis       Target axis: PC2    Affected axis       Target axis: PCA    Affected axis                Control effect (d): layer 1\n 2  0.2                         LR           20.2                      PC1          20.2                       PC1          30.2                       PC1           PC512        -0.00  0.00   0.00   -0.00 -0.00-0.00  -0.0o\n 8                              PC1   8                                PC2   3                                 PC2   8                                 PC2\n                                PC2                                    PC4                                     PC4                                     PC4                                                               I1e-5\n    0.0                         PC4           0.0                      PC8           0.0                       PC8           0.0                       PC8           PC128        -0.00  -0.00  -0.00  0.00  0.00 -0.00  0.00\n                                PC8   8                                PC32                                    PC32  8                                 PC32\n                                PC32                                   PC128                                   PC128                                   PC128\n   -0.2                         PC128        -0.2                      PC512        -0.2                       PC512        -0.2                       PC512          PC32        0.00          0.00   0.00  -0.00-0.00  0.00   5\n              100         200   PC512               100    200                             100           200                       100           200                8  PC8        -0.00  0.00\n              #Examples                             #Examples                              #Examples                               #Examples                        1  PC4        0.00   0.00   -0.00  -0.00 -0.00 0.00  0.00\n             Target axis: PC8  Affected axis       Target axis: PC32  Affected axis       Target axis: PC128  Affected axis       Target axis: PC512  Affected axis    PC2        0.00   0.00   -0.00  0.00  -0.00 0.00  0.00\n 2  0.2                         PC1   2       0.2                      PC1          20.2                       PC1          30.2                       PC1                               0.00   0.00   0.00  0.00 -0.00  0.00   5\n 3                              PC2                                    PC2                                     PC2                                     PC2\n                                PC4   3                                PC4   3                                 PC4   3                                 PC4             PC1        0.00   -0.00  0.00   0.00  0.00 -0.00  -0.00\n                                PC8           0.0                      PC8           0.0                       PC8           0.0                       PC8\n                                PC32  8                                PC32                                    PC32  8                                 PC32\n                                PC128                                  PC128                                   PC128                                   PC128            LR -0.00  0.00   -0.00  -0.00  0.00  0.00  0.00  0.00\n   -0.2                         PC512        -0.2                      PC512        -0.2                       PC512        -0.2                       PC512\n              100         200                       100    200                             100           200                       100           200                         LR   PC1    PC2    PC4    PC8 PC32 PC128PC512\n              #Examples                             #Examples                              #Examples                               #Examples                                              Affected axis\n                   Figure A.9: Control performance of Llama3.1 8B (implicit control) in layer 1.\n             Target axis: LR   Affected axis       Target axis: PC1   Affected axis       Target axis: PC2    Affected axis       Target axis: PC4    Affected axis               Control effect (d): layer 16\n 2  5.0                         LR          2 2.0                      PC1         2 4.0                       PC1 0                                   PC1           PC512        -0.38  -0.56  -0.23  -0.24 -0.11 0.10  -0.04\n 3                              PC1                                    PC2                                     PC2           1.0                       PC2\n                                PC2   3                                PC4   3                                 PC4                                     PC4\n    2.5                         PC4           1.0                      PC8           2.0                       PC8                                     PC8\n 8                              PC8   8                                PC32  8                                 PC32                                    PC32          PC128        0.38   0.34   -0.28  -0.18 -0.23-0.08  0.33   4\n 00.0                           PC328         0.0                      PC522         0.0                       PCS22         0.0                              PC522   PC32        -0.36  0.53   0.11   0.14  0.23 -0.06  -0.08\n              100         200   PC512               100   200                              100           200                       100  200                         8  PC8        -0.07  0.24   -0.22  1.90  0.17  0.00  0.12   2\n              #Examples                             #Examples                              #Examples                              #Examples                         1  PC4        0.12   0.14   1.36   -0.00 -0.46-0.23  -0.52  0\n            Target axis: PC8   Affected axis  1.0  Target axis: PC32  Affected axis       Target axis: PC128  Affected axis       Target axis: PC512  Affected axis    PC2        1.22   4.27   -0.61  1.24  0.08 -0.33  0.32   ~2\n 3 2.0                          PC1   2                                PC1   2       0.5                       PC1          20.5                       PC1\n 3                              PC2   3       0.5                      PC2   3                                 PC2   3                                 PC2\n                                PC4                                    PC4                                     PC4           0.0                       PC4             PC1        1.23   0.98   -0.05  0.38  0.04 -0.40  0.38\n    1.0                         PC8                                    PC8           0.0                       PC8                                     PC8\n                                PC32  8       0.0                      PC32  3                                 PC32  8                                 PC32\n                                PC128                                  PC128                                   PC128        -0.5                       PC128            LR  5.30  0.45   3.04   0.40   0.03  -0.16-0.14  -0.18\n    0.0       100         200   PC512        -0.5   100    200         PC512  -0.5         100           200   PC512        -1.0   100           200   PC512                 LR   PC1    PC2    PC4    PC8 PC32 PC128PC512\n              #Examples                             #Examples                              #Examples                               #Examples                                              Affected axis\n                                                                                                                                        Figure A.10: Control performance of Llama3.1 8B (explicit control) in layer 16.\n                                                                                                               23",
    "metadata": {
      "page": 23
    }
  },
  {
    "page_or_section_index": 24,
    "text": "            Target axis: LR  Affected axis     Target axis: PC1  Affected axis     Target axis: PC2   Affected axis          0.5     Target axis: PC4  Affected axis         Control effect (d): layer 16\n3                              LR           2 0.5                       PC1     0                             PC1    0                                    PC1    PC512       -0.10  -0.20 0.01  -0.05 -0.00  0.00-0.06\n31.0                           PC1          3                           PC2      1.0                          PC2                                         PC2\n                               PC2                                      PC4                                   PC4                                         PC4\n                               PC4                                      PC8                                   PC8            0.0                          PC8\n8                              PC8          3                             PC32  3                              PC32  83                                   PC32   PC128       -0.16  -0.23 -0.07 0.08  -0.08  0.03-0.09  1.0\n   0.0                         PC32          0.0                         PC128   0.0                          PC128                                       PC128\n                               PC128                                     PC512                                PC512                                       PC512   PC32                    -0.01 -0.01 0.15   0.02\n             100    200        PC512                100     200                      100    200                      -0.5     100    200                   9       PC8       -0.03  0.08                         -0.06  0.5\n            #Examples                           #Examples                            #Examples                                          #Examples                  PC4       0.03   0.06  -0.12 0.55  0.08  -0.12 0.20  0.0\n   1.0      Target axis: PC8  Affected axis   Target axis: PC32  Affected axis             Target axis: PC128  Affected axis        Target axis: PC512  Affected axis        0.08   0.08  0.30  -0.09 0.01   0.08-0.21  -0.5\n8                              PC1           0                           PC1     0                              PC1          00.2                          PC1     PC2       0.53   1.16  -0.23 0.33  -0.05-0.39  0.32\n3  0.5                         PC2             0.2                       PC2                                    PC2                                        PC2\n                               PCS             0.0                       PC8          0.0                       PC8            0.0                         PC8  PC1          0.48   0.26  0.05  0.26  0.10  -0.08 0.09  -1.0\n8                              PC32          8                           PC32    3                              PC32         8                             PC32\n   0.0                         PC128                                     PC128                                  PC128         -0.2                         PC128    LR 0.89  0.37   1.08  0.01  -0.06 0.02  -0.27 0.16\n   -0.5       100    200       PC512          -0.2   100  200            PC512       -0.5  100            200   PC512         -0.5  100            200     PC512  LR         PC1    PC2   PC4   PC8PC32 PC128PC512\n             #Examples                              #Examples                         #Examples                               #Examples                                                Affected axis\n                Figure A.11: Control performance of Llama3.1 8B (implicit control) in layer 16.\n            Target axis: LR   Affected axis    1.0  Target axis: PC1   Affected axis  Target axis: PC2         Affected axis  Target axis: PC4           Affected axis       Control effect (d): layer 32\n2 4.0                          LR            3                           PC1     3                              PC1          2                             PC1        PC512     -0.25  -0.23  -0.15  0.19   -0.17-0.19   -0.06\n3                              PC1          8  0.5                       PC2     8    2.0                       PC2           82.0                         PC2\n                               PC2                                       PC4                                    PC4                                        PC4\n   2.0                         PC4                                       PC8                                    PC8                                        PC8\n8                              PC8           8 0.0                       PC32        30.0                       PC32         8                             PC32       PC128     -0.10  0.27   0.05   -0.221 0.03   0.17  0.19\n                               PC32                                      PC128                                  PC128                                      PC128\n0  0.0                         PC128          -0.5                       PC512                                  PC512          0.0                         PC512       PC32     -0.14         0.06   -0.23  0.32   0.06  0.16\n             100     200       PC512                 100  200                        -2.0   100           200                        100           200      8           PC8     -0.09  0.87                              2\n             #Examples                               #Examples                            #Examples                                 #Examples               1           PC4     -0.29  -0.66  -0.18  1.78   -0.08 -0.53  -0.31\n   2.0      Target axis: PC8  Affected axis         Target axis: PC32  Affected axis       Target axis: PC128  Affected axis        Target axis: PC512   Affected axis  PC2     -0.02  0.24   2.55   -0.29  0.44   0.88  0.49\n2                              PC1            21.0                       PC1     2                              PC1          30.5                          PC1                         2.91   1.27   -0.93  0.49   0.13  -0.36\n3   1.0                        PC2                                       PC2          0.5                       PC2                                        PC2\n                               PC4           3 0.5                       PC4     3                              PC4          3                             PC4          PC1      0.03  0.09   -0.40  0.49   0.31   0.21  0.41\n                               PC8                                       PC8                                    PC8            0.0                         PC8\n   0.0                         PC32          8 0.0                       PC32         0.0                       PC32         8                             PC32\n                               PC128                                     PC128                                  PC128                                      PC128         LR 4.47-0.45  -0.19  1.03   -0.01  1.05   1.34  0.60\n   -1.0       100    200       PC512          -0.5   100  200            PC512       -0.5   100           200   PC512         -0.5   100           200     PC512             LR  PC1   PC2    PC4    PC8 PC32 PC128PC512\n             #Examples                               #Examples                            #Examples                                 #Examples                                          Affected axis\n                Figure A.12: Control performance of Llama3.1 8B (explicit control) in layer 32.\n   2.0      Target axis: LR   Affected axis     Target axis: PC1       Affected axis  1.0  Target axis: PC2  Affected axis    Target axis: PC4          Affected axis        Control effect (d): layer 32\n2                              LR            8                           PC1     3                              PC1          01.0                          PC1        PC512     -0.10  0.03   -0.11  0.08   -0.00 -0.08  0.06\n3                              PC1             0.2                       PC2                                    PC2                                        PC2\n   1.0                         PCR           3                           PC8     3                              PC8                                        PC8\n8                              PC8             0.0                       PC32        80.0                       PC32         8                             PC32       PC128     -0.10  -0.11  0.04   0.15   -0.02  0.06  0.00\n   0.0                         PC32                                      PC128                                  PC128          0.0                         PC128\n                               PC128         -0.22                       PC512                                  PC512                                      PC512\n             100     200       PC512                 100  200                             100  200                                 100             200      3          PC32      0.08  0.16   0.03   -0.07  0.15   0.00  -0.01\n             #Examples                               #Examples                         #Examples                                   #Examples                1           PC8     -0.16  -0.01  ~0.23  0.70   -0.04 -0.19  0.09\n    1.0     Target axis: PC8  Affected axis    0.5  Target axis: PC32  Affected axis  0.5  Target axis: PC128  Affected axis   0.5  Target axis: PC512  Affected axis   PC4      0.12  -0.19  0.94   -0.32  0.09   0.37  -0.09\n2                              PC1           3                           PC1     0                              PC1          2                             PC1          PC2      0.13  0.72   0.31   -0.54  0.27  -0.04  -0.09\n3  0.5                         PC2                                       PC2                                    PC2            0.2                         PC2\n                               PC4           3                           PC4                                    PC4          3                             PC4          PC1      0.12  -0.06  -0.03  0.13   -0.02  0.06  0.10\n                               PC8                                       PC8                                    PC8                                        PC8\n8                              PC32           80.0                       PC32        80.0                       PC32         3 0.0                         PC32\n                               PC128                                     PC128                                  PC128                                      PC128         LR 1.86 0.16  -0.50  0.60   -0.20  0.19   0.52  0.16\n                               PC512                                     PC512                                  PC512         -0.2                         PC512\n   -0.5       100    200                             100  200                          100                200                        100           200           LR              PC1   PC2    PC4    PC8 PC32 PC128PC512\n             #Examples                               #Examples                        #Examples                                    #Examples                                           Affected axis\n                Figure A.13: Control performance of Llama3.1 8B (implicit control) in layer 32.\n                                                                                                                24",
    "metadata": {
      "page": 24
    }
  },
  {
    "page_or_section_index": 25,
    "text": "   2.0      Target axis: LR   Affected axis        Target axis: PC1   Affected axis    0    Target axis: PC2     Affected axis     1.0  Target axis: PC4  Affected axis                   Control effect (d): layer 1\n2                              LR           2                       PC1              01.                      PC1                2                          PC1          PC512           0.30  -0.03 0.22  0.03  0.28  -0.29  0.11\n3  1.0                         PC1          8 1.0                   PC2                                       PC2                  0.5                      PC2\n                               PC2                                  PC4                                       PC4                3                          PC4\n                               PC4                                  PC8                 0.0                   PC8                                           PC8          PC128           0.42  -0.10 0.06  -0.34 0.12  -0.08  -0.01\n   0.0                         PC8            0.0                   PC32             3                        PC32               8 0.0                      PC32\n                               PC32                                 PC128                                     PC128                                         PC128\n   -1.0                        PC128                                PC512                                     PC512                                         PC512         PC32     -0.13       0.31  0.05  -0.13  -0.10-0.03  -0.33\n             100     200       PC512          -1.0   100    200                               100  200                            -0.5   100  200            8             PC8           0.63  -0.19 0.38  0.34  0.38  -0.22  0.18\n             #Examples                               #Examples                                    #Examples                             #Examples            1             PC4           0.65  -0.19 0.55  -0.19 0.22   0.09  0.05\n            Target axis: PC8  Affected axis   0.5  Target axis: PC32  Affected axis           Target axis: PC128 Affected axis     0.5  Target axis: PC512  Affected axis  PC2           0.73  -0.37 0.17  -0.38 -0.34 -0.01  0.38\n2                              PC1          2                       PC1                20.5                   PC1                3                          PC1\n3  0.5                         PC2          3                       PC2              3                        PC2                3                          PC2\n                               PC4                                  PC4                                       PC4                                           PC4            PC1           1.46  -0.99-0.07  0.07  -0.50  0.10  0.53\n                               PC8            0.0                   PC8                                       PC8                                           PC8\n   0.0                         PC32         8                       PC32                0.0                   PC32               8 0.0                      PC32\n                               PC128                                PC128                                     PC128                                         PC128           LR     1.58  1.08  0.96 -0.29  0.33  0.58  -0.55  -0.57\n   -0.5                        PC512          -0.5                  PC512             -0.5                    PC512               -0.5                      PC512\n             100     200                             100    200                               100        200                             100           200                          LR   PC1   PC2    PC4  PC8 PC32 PC128PC512\n             #Examples                               #Examples                                #Examples                                  #Examples                                             Affected axis\n                                                     Figure A.14: Qwen2.5 7B (explicit control) layer 1\n            Target axis: LR   Affected axis        Target axis: PC1  Affected axis    Target axis: PC2        Affected axis         Target axis: PCA  Affected axis                Control effect (d): layer 1\n2  0.2                         LR           0 0.2                   PC1             20.2                     PC1                  0.2                      PC1       PC512         -0.00 -0.00 -0.000.00-0.00    0.00  -0.00\n3                              PC1                                  PC2                                               PC2                                  PC2\n   0.0                         PC4            0.0                   PCS             3 0.0                             PCA         0.0                      PC8\n                               PC8          8                                 PC32  8                                  PC32                                PC32      PC128         0.00   0.00   0.000.00  0.00   0.001-0.00   0.00010\n                               PC32                                          PC128                                    PC128                                     PC128\n   -0.2                        PC128          -0.2                           PC512   -0.2                             PC512       -0.2                          PC512 PC32           -0.00-0.00 -0.000.00  0.00    0.00-0.00\n             100     200       PC512                 100  200                                100         200                            100      200        8         PC8          -0.00-0.00~0.00|-0.000.00     -0.001-0.00   0.00005\n             # Examples                              #Examples                               #Examples                                 #Examples                      PC4          0.00   0.00       0.00-0.00-0.00-0.000.00   0.00000\n           Target axis: PC8   Affected axis    Target axis: PC32     Affected axis        Target axis: PC128  Affected axis       Target axis: PC512  Affected axis   PC2          -0.00  0.00   0.000.00    -0.00-0.00-0.00   ~0.00005\n3  0.2                         PC1          3 0.2                   PC1             3 0.2                    PC1                2 0.2                      PC1\n3                              PC2                                  PC2                                               PC2                                  PC2\n                               PC4          8                       PC4             3                         PC4               3                          PC4        PC1             -0.00-0.00-0.000.00  -0.000.00    0.00   ~0.00010\n   0.0                         PC8            0.0                   PC8               0.0                     PC8                 0.0                      PC8\n                               PC32         3                                 PC32  I                                  PC32     3                          PC32\n                               PC128                                         PC128                                    PC128                                     PC128  LR     0.00 0.00-0.00     0.000.00  -0.00 -0.001-0.00\n   -0.2                        PC512          -0.2                           PC512     -0.2                           PC512       -0.2                          PC512\n             100     200                             100  200                                100         200                            100      200                           LR  PC1              PC2 PC4PC8 PC32PC12PC512\n             #Examples                               #Examples                               #Examples                                 # Examples                                              Affected axis\n                                                     Figure A.15: Qwen2.5 7B (implicit control) layer 1\n   4.0     Target axis: LR    Affected axis   1.0  Target axis: PC1   Affected axis         Target axis: PC2      Affected axis    2.0  Target axis: PC4  Affected axis                   Control effect (d): layer 14\n2                              LR           2                       PC1              0                        PC1                2                          PC1          PC512           0.06  -0.58-0.42  0.05  0.13   0.19  0.17\n3                              PC1          3                       PC2                 2.0                   PC2                3                          PC2\n   2.0                         PC2                                  PC4                                       PC4                  1.0                      PC4\n                               PC4                                  PC8                                       PC8                                           PC8          PC128           0.11  -0.07 0.09  -0.17 0.15  -0.14  -0.01\n1                              PC8            0.0                   PC32                                      PC32                                          PC32\n   0.0                         PC328                                PC522               0.0                   PC52Z                0.0                          PC522     PC32           -0.17 0.53  0.17  -0.27 0.02  -0.19  -0.38  2\n             100     200       PC512          -1.0   100   200                                100  200                           0-1.0   100           200  9              PC8           -0.40 -0.44 0.37  1.01  0.16  -0.00  0.30\n             #Examples                               Examples                                 Examples                                   Examples\n                                                     #                                       #                                          #\n           Target axis: PC8   Affected axis        Target axis: PC32  Affected axis           Target axis: PC128  Affected axis         Target axis: PC512  Affected axis  PC4           -0.42 0.47  1.58  0.25  0.36  -0.53  0.02\n2  1.0                         PC1          2                       PC1              3  0.5                   PC1                0 0.5                      PC1            PC2           0.17  2.54  1.09  0.40   -0.08-0.28  -0.89  2\n3                              PC2          8 0.5                   PC2              3                        PC2                                           PC2\n                               PC4                                  PC4                                       PC4                                           PC4            PC1           0.86  0.79  0.59  0.40  0.03   0.12  -0.64\n                               PC8                                  PC8                                       PC8                                           PC8\n80.0                           PC32         3 0.0                   PC32             8  0.0                   PC32               3                          PC32\n                               PC128                                PC128                                     PC128               -0.5                      PC128           LR 3.54      0.54  2.48  1.78  0.48  -0.14  0.03  -0.74\n                               PC512          -0.5                  PC512                                     PC512                                         PC512\n             100     200                             100   200                         -0.5   100        200                             100           200                       LR      PC1   PC2 PC4 PC8 PC32 PC128PC512\n             #Examples                               #Examples                                #Examples                                  #Examples                                             Affected axis\n                                                   Figure A.16: Qwen2.5 7B (explicit control) layer 14\n                                                                                                              25",
    "metadata": {
      "page": 25
    }
  },
  {
    "page_or_section_index": 26,
    "text": "            Target axis: LR    Affected axis       Target axis: PC1  Affected axis      Target axis: PC2          Affected axis   Target axis: PCA       Affected axis                             Control effect (d): layer 14\n3  0.2                         LR            2 0.2                 PC1                 2 0.2                           PC1       30.2                      PC1          PC512  -0.00-0.00      0.00                0.00-0.00-0.00     -0.00\n3                              PC1           3                     PC2                 3                               PC2      3                          PC2\n                               PC2                                 PC4                                                 PC4                                 PC4\n   0.0                              PC4        0.0                 PC8                   0.0                           PC8        0.0                      PC8          PC128     -0.00               0.00-0.00 -0.00 -0.00  0.00     -0.00    0.0050\n                               PC8           3                     PC32                3                               PC32                                       PC32\n                               PC32                                PC128                                              PC128                                      PC128\n  -0.2       100     200       PC522          -0.2   100  200      PC512                -0.2  100      200            PC512      -0.2   100         200          PC512 9  PC32     0.00  -0.00 0.00 0.00                    0.00-0.00 0.00     0.0025\n             #Examples                               #Examples                                #Examples                                 #Examples                          PC8     0.00  -0.00 0.00 0.00                    0.00-0.00 0.00     0.0000\n             Target axis: PC8  Affected axis   Target axis: PC32  Affected axis         Target axis: PC128  Affected axis            Target axis: PC512  Affected axis     PC4     0.00  -0.00 0.00 0.00                    0.00-0.00 -0.00    ~0.0025\n8  0.2                         PC1           8 0.2                 PC1                 8 0.2                           PC1      8 0.2                      PC1             PC2    -0.00               0.00-0.00 -0.00 -0.00 0.00-0.01\n8                              PC2  8                              PC2                 8                               PC2      8                          PC2\n                               PC4                                 PC4                                                 PC4                                 PC4            PC1      0.00               0.00~0.00 -0.00 -0.00  0.00     -0.00    ~0.0050\n   0.0                         PC8            0.0                  PC8                   0.0                           PC8        0.0                      PC8\n                               PC32          8                     PC32                8                               PC32     8                                 PC32\n                               PC128                               PC128                                              PC128                                      PC128     LR 0.00-0.00  0.00  0.00 0.00             0.00    0.00     -0.00\n  -0.2                         PC512          -0.2                 PC512                -0.2                          PC512      -0.2                            PC512\n             100     200                             100  200                                 100      200                              100         200                   LR        PC1  PC2 PC4    PC8PC32 PC128C512\n             #Examples                               #Examples                                #Examples                                 #Examples                                                         Affected axis\n                                                                                                                                    Figure A.17: Qwen2.5 7B (implicit control) layer 14\n            Target axis: LR  Affected axis         Target axis: PC1  Affected axis      Target axis: PC2  Affected axis           4.0  Target axis: PC4     Affected axis             Control effect (d): layer 28\n3 5.0                          LR            0                              PC1         0                         PC1            0                         PC1               PC512    0.09  -0.02  0.40              -0.36  0.43     -0.31  0.31\n3                              PC1             0.5                          PC2          1.0                      PC2                                              PC2\n  2.5                          PCZ             0.0                          PC8                                   PCS             2.0                              PC8       PC128    0.34   0.25  0.63               0.12  0.39     -0.28  0.43\n1                              PC8                                         PC32                                   PC32                                               PC32                                                                           4\n                               PC32                                              PC128   0.0                      PC128                                             PC128\n0  0.0                         PC128          -0.5                               PC512                            PC512           0.0                               PC512     PC32    -0.82  0.00  -0.92             -0.07  -0.03     0.07  -0.53\n             100     200       PC512                  100  200                                 100           200                         100           200  9                 PC8     -0.20  0.27  0.23               1.50  -0.24     0.05  0.41  2\n             #Examples                                Examples                                 Examples                                 #Examples\n             Target axis: PC8                         #                                       #                                                                               PC4     1.19   0.30  3.71               0.22  0.37     -0.83  1.08    0\n                               Affected axis          Target axis: PC32  Affected axis        Target axis: PC128  Affected axis    1.0  Target axis: PC512  Affected axis     PC2     0.21   1.27  0.28              -0.05  -0.01-0.05      0.48    -2\n2                              PC1           0                     PC1                  0                         PC1            0                                 PC1\n3  1.0                         PC2                                 PC2                   0.5                      PC2              0.5                             PC2\n                               PCA             0.0                 PCA                                            PC8                                              PCA        PC1     0.35  -0.37  -0.34              0.13  0.28      0.16  -0.43   -4\n8                              PC32          8                     PC32                 80.0                      PC32           3 0.0                               PC32\n                               PC128                               PC128                                          PC128                                             PC128  LR  5.72   1.71  -0.34  3.19               0.25  0.66     -0.86  1.38\n   0.0       100    200        PC512          -1.0   100  200      PC512                -0.5   100           200  PC512           -0.5   100           200          PC512        LR   PC1     PC2  PC4 PC8 PC32 PC128PC512\n             #Examples                                    #Examples                           #Examples                                  #Examples                                             Affected axis\n                                                     Figure A.18: Qwen2.5 7B (explicit control) layer 28\n           Target axis: LR     Affected axis       Target axis: PC1  Affected axis       0.5   Target axis: PCZ   Affected axis   1.0  Target axis: PC4     Affected axis             Control effect (d): layer 28\n2                              LR            3 0.2                 PC1                 0                PC1       0                                        PC1           PC512       0.03   -0.04              0.14  -0.05    -0.01  0.00   0.06\n31.0                           PC1                                 PC2                   0.2                           PC2                                         PC2\n                               PC2           3                     PC4                                                 PC4        0.5                              PC4\n                               PC4             0.0                 PC8                                                 PC8                                         PC8   PC128       0.05   -0.01              0.11  -0.04     0.05  0.01   0.04  1.0\n 8                             PC8           8                     PC32                8 0.0                           PC32                                       PC32\n   0.0                         PC32                                PC128                                          PC128           0.0                            PC128\n                               PC128          -0.2                 PC512                -0.2                      PC512                                          PC512    PC32       -0.08  0.08              -0.21  0.05     -0.00  0.02  -0.04\n             100    200        PC512                 100  200                                 100  200                           -0.5   100  200           9               PC8       -0.02  -0.05             -0.03  0.25     -0.08  0.05   0.15  0.5\n            #Examples                                #Examples                                    #Examples                       #Examples                                                                                                       0.0\n             Target axis: PC8  Affected axis       Target axis: PC32  Affected axis      0.4  Target axis: PC128  Affected axis         Target axis: PC512  Affected axis  PC4       0.22   -0.11              0.72  -0.20    -0.03  0.03   0.14  -0.5\n8  0.5                         PC1            00.2                 PC1                 2                               PC1       0                                 PC1     PC2       0.09   0.21               0.04  -0.11     0.01  -0.01  0.02\n3  0.2                         PC2                                 PC2                   0.2                           PC2        0.2                              PC2\n                               PC4             0.0                 PC4                 3                               PC4                                         PC4    PC1        0.06   -0.07              0.00  0.04      0.08  -0.02 -0.12  -1.0\n                               PC8                                 PC8                                                 PC8                                         PC8\n   0.0                         PC32          8                     PC32                3 0.0                      PC32           80.0                             PC32\n                               PC128          -0.2                 PC128                                          PC128                                             PC128   LR 1.42  0.29   -0.25              0.77  -0.14     0.05  -0.07  0.15\n  -0.2        100    200       PC512          -0.5   100  200      PC512                -0.2  100            200  PC512          -0.2   100            200       PC512    LR         PC1    PC2                PC4            PC8PC32 PC128PC512\n             #Examples                               #Examples                                #Examples                                 #Examples                                              Affected axis\n                                                   Figure A.19: Qwen2.5 7B (implicit control) layer 28\n                                                                                                                  26",
    "metadata": {
      "page": 26
    }
  },
  {
    "page_or_section_index": 27,
    "text": "A.4.7   Metaphorical illumination\nFigure A.20: Metaphorical illumination. Metaphorically, neural mechanisms in the neural space\ncan be considered as small objects floating in a dark room.  We aim to characterize the scope\nand resolution of second-order metacognitive mechanisms (which enable the reporting and control\nperformance; represented by blue and green searchlight objects) in illuminating specified first-order\nneural mechanisms (other objects). We expect that the emergent metacognitive mechanisms can be\nremarkably flexible (e.g., reorienting the light beams). In comparison, standard ICL does not clearly\ndistinguish between the first- and second-order mechanisms.\n                                              27",
    "metadata": {
      "page": 27
    }
  }
]